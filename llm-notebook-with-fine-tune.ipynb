{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Open Source Llama 2 in Snowpark Container Services "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.model.models import llm\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "from snowflake.snowpark import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Update SNOWFLAKE_WAREHOUSE, SNOWFLAKE_COMPUTE_POOL, HUGGING_FACE_TOKEN before proceeding.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SNOWFLAKE_DATABASE  = os.getenv(\"SNOWFLAKE_DATABASE\")\n",
    "SNOWFLAKE_SCHEMA    = os.getenv(\"SNOWFLAKE_SCHEMA\")\n",
    "SNOWFLAKE_WAREHOUSE = 'DASH_L'\n",
    "SNOWFLAKE_COMPUTE_POOL = 'DASH_GPU3'\n",
    "HUGGING_FACE_TOKEN = 'xxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Secure Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 3.7.0, Python Version: 3.10.11, Platform: Linux-5.4.181-99.354.amzn2.x86_64-x86_64-with-glibc2.35\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "INFO:snowflake.snowpark.session:Snowpark Session information: \n",
      "\"version\" : 1.12.0,\n",
      "\"python.version\" : 3.10.11,\n",
      "\"python.connector.version\" : 3.7.0,\n",
      "\"python.connector.session.id\" : 18047963680641034,\n",
      "\"os.name\" : Linux\n",
      "\n",
      "INFO:snowflake.connector.cursor:query: [alter session set PYTHON_SNOWPARK_USE_SQL_SIMPLIFIER = True]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role                        : \"DASH_SPCS\"\n",
      "Database                    : \"DASH_DB\"\n",
      "Schema                      : \"DASH_SCHEMA\"\n",
      "Warehouse                   : \"DASH_L\"\n",
      "Snowpark for Python version : 1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Read the login token supplied automatically by Snowflake. These tokens are short lived and should always be read right before creating any new connection.\n",
    "def get_login_token():\n",
    "  with open(\"/snowflake/session/token\", \"r\") as f:\n",
    "    return f.read()\n",
    "\n",
    "# Construct Snowflake connection params from environment variables.\n",
    "def get_connection_params():\n",
    "  return {\n",
    "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"host\": os.getenv(\"SNOWFLAKE_HOST\"),\n",
    "    \"warehouse\": SNOWFLAKE_WAREHOUSE,\n",
    "    \"database\": SNOWFLAKE_DATABASE,\n",
    "    \"schema\": SNOWFLAKE_SCHEMA,\n",
    "    \"authenticator\": \"oauth\",\n",
    "    \"token\": get_login_token()\n",
    "  }\n",
    "\n",
    "# Create Snowflake Session object\n",
    "session = Session.builder.configs(get_connection_params()).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Llama 2 from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enable INFO log level\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "options = llm.LLMOptions(token=HUGGING_FACE_TOKEN,max_batch_size=100,)\n",
    "llama_model = llm.LLM(model_id_or_path=\"meta-llama/Llama-2-7b-chat-hf\",options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register, Log and Deploy Llama 2 into Snowpark Container Services \n",
    "\n",
    "*NOTE: Logging and deploying the same model are one time operations. Once the model is logged and deployed, use ModeReference to get the reference to the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97/1196839145.py:4: DeprecationWarning: \n",
      "The `snowflake.ml.registry.model_registry.ModelRegistry` has been deprecated starting from version 1.2.0.\n",
      "It will stay in the Private Preview phase. For future implementations, kindly utilize `snowflake.ml.registry.Registry`,\n",
      "except when specifically required. The old model registry will be removed once all its primary functionalities are\n",
      "fully integrated into the new registry.\n",
      "        \n",
      "  registry = model_registry.ModelRegistry(\n",
      "INFO:snowflake.connector.cursor:query: [SHOW DATABASES LIKE 'DASH_DB']\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "WARNING:absl:The database DASH_DB already exists. Skipping creation.\n",
      "INFO:snowflake.connector.cursor:query: [SHOW SCHEMAS LIKE 'DASH_SCHEMA' IN DATABASE DASH_DB]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "WARNING:absl:The schema DASH_DB.DASH_SCHEMA already exists. Skipping creation.\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 13\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 8\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 9\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_ARTIFACTS]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 7\n",
      "INFO:snowflake.connector.cursor:query: [SHOW DATABASES LIKE 'DASH_DB']\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW SCHEMAS LIKE 'DASH_SCHEMA' IN DATABASE DASH_DB]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_MODELS' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_METADATA' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_DEPLOYMENTS' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_ARTIFACTS_...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME    = \"LLAMA2_7b_CHAT\"\n",
    "MODEL_VERSION = \"BaseV1.1\"\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=SNOWFLAKE_DATABASE, \n",
    "    schema_name=SNOWFLAKE_SCHEMA, \n",
    "    create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATION_CONTEXT</th>\n",
       "      <th>CREATION_ENVIRONMENT_SPEC</th>\n",
       "      <th>CREATION_ROLE</th>\n",
       "      <th>CREATION_TIME</th>\n",
       "      <th>ID</th>\n",
       "      <th>INPUT_SPEC</th>\n",
       "      <th>NAME</th>\n",
       "      <th>OUTPUT_SPEC</th>\n",
       "      <th>RUNTIME_ENVIRONMENT_SPEC</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>URI</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>ARTIFACT_IDS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>METRICS</th>\n",
       "      <th>TAGS</th>\n",
       "      <th>REGISTRATION_TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.10.13\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-14 15:29:38.425000-08:00</td>\n",
       "      <td>a9b776ce834511ee9c921204c7b8f46d</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_A9B776CE834511EE9C921204C7B8F46D</td>\n",
       "      <td>BaseV1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-14 15:29:39.837000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.10.11\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2024-03-27 14:02:19.556000-07:00</td>\n",
       "      <td>4a0ec9baec7d11ee95b1369145349ce2</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_4A0EC9BAEC7D11EE95B1369145349CE2</td>\n",
       "      <td>BaseV1.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-27 14:02:20.639000-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.8.16\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-15 11:04:42.250000-08:00</td>\n",
       "      <td>d26762d883e911ee8f5ace7db0e7935f</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D26762D883E911EE8F5ACE7DB0E7935F</td>\n",
       "      <td>BestTunedV1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-15 11:04:44.853000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.18\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-14 16:49:14.883000-08:00</td>\n",
       "      <td>c6ca82aa835011eeac5d1204c7b8f46d</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C6CA82AA835011EEAC5D1204C7B8F46D</td>\n",
       "      <td>BaseV2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-14 16:49:16.186000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.18\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-27 06:38:13.856000-08:00</td>\n",
       "      <td>934a1d828d3211ee9d301204c7b8f46e</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_934A1D828D3211EE9D301204C7B8F46E</td>\n",
       "      <td>NewBaseV2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-27 06:38:15.860000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.10.11\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2024-03-06 16:16:55.387000-08:00</td>\n",
       "      <td>ff92534adc1711ee93c05ad1a0b84c26</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_FF92534ADC1711EE93C05AD1A0B84C26</td>\n",
       "      <td>FineTunedV1.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-06 16:16:56.386000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.18\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-16 09:23:06.204000-08:00</td>\n",
       "      <td>c70d0bf284a411eebb681204c7b8f46d</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C70D0BF284A411EEBB681204C7B8F46D</td>\n",
       "      <td>NewBaseV1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-16 09:23:07.145000-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREATION_CONTEXT    CREATION_ENVIRONMENT_SPEC CREATION_ROLE  \\\n",
       "0             None  {\\n  \"python\": \"3.10.13\"\\n}   \"DASH_SPCS\"   \n",
       "1             None  {\\n  \"python\": \"3.10.11\"\\n}   \"DASH_SPCS\"   \n",
       "2             None   {\\n  \"python\": \"3.8.16\"\\n}   \"DASH_SPCS\"   \n",
       "3             None   {\\n  \"python\": \"3.9.18\"\\n}   \"DASH_SPCS\"   \n",
       "4             None   {\\n  \"python\": \"3.9.18\"\\n}   \"DASH_SPCS\"   \n",
       "5             None  {\\n  \"python\": \"3.10.11\"\\n}   \"DASH_SPCS\"   \n",
       "6             None   {\\n  \"python\": \"3.9.18\"\\n}   \"DASH_SPCS\"   \n",
       "\n",
       "                     CREATION_TIME                                ID  \\\n",
       "0 2023-11-14 15:29:38.425000-08:00  a9b776ce834511ee9c921204c7b8f46d   \n",
       "1 2024-03-27 14:02:19.556000-07:00  4a0ec9baec7d11ee95b1369145349ce2   \n",
       "2 2023-11-15 11:04:42.250000-08:00  d26762d883e911ee8f5ace7db0e7935f   \n",
       "3 2023-11-14 16:49:14.883000-08:00  c6ca82aa835011eeac5d1204c7b8f46d   \n",
       "4 2023-11-27 06:38:13.856000-08:00  934a1d828d3211ee9d301204c7b8f46e   \n",
       "5 2024-03-06 16:16:55.387000-08:00  ff92534adc1711ee93c05ad1a0b84c26   \n",
       "6 2023-11-16 09:23:06.204000-08:00  c70d0bf284a411eebb681204c7b8f46d   \n",
       "\n",
       "  INPUT_SPEC            NAME OUTPUT_SPEC RUNTIME_ENVIRONMENT_SPEC TYPE  \\\n",
       "0       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "1       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "2       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "3       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "4       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "5       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "6       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "\n",
       "                                                                       URI  \\\n",
       "0  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_A9B776CE834511EE9C921204C7B8F46D   \n",
       "1  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_4A0EC9BAEC7D11EE95B1369145349CE2   \n",
       "2  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D26762D883E911EE8F5ACE7DB0E7935F   \n",
       "3  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C6CA82AA835011EEAC5D1204C7B8F46D   \n",
       "4  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_934A1D828D3211EE9D301204C7B8F46E   \n",
       "5  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_FF92534ADC1711EE93C05AD1A0B84C26   \n",
       "6  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C70D0BF284A411EEBB681204C7B8F46D   \n",
       "\n",
       "         VERSION ARTIFACT_IDS DESCRIPTION METRICS  TAGS  \\\n",
       "0       BaseV1.0         None        None    None  None   \n",
       "1       BaseV1.1         None        None    None  None   \n",
       "2  BestTunedV1.0         None        None    None  None   \n",
       "3       BaseV2.0         None        None    None  None   \n",
       "4    NewBaseV2.0         None        None    None  None   \n",
       "5  FineTunedV1.1         None        None    None  None   \n",
       "6    NewBaseV1.0         None        None    None  None   \n",
       "\n",
       "            REGISTRATION_TIMESTAMP  \n",
       "0 2023-11-14 15:29:39.837000-08:00  \n",
       "1 2024-03-27 14:02:20.639000-07:00  \n",
       "2 2023-11-15 11:04:44.853000-08:00  \n",
       "3 2023-11-14 16:49:16.186000-08:00  \n",
       "4 2023-11-27 06:38:15.860000-08:00  \n",
       "5 2024-03-06 16:16:56.386000-08:00  \n",
       "6 2023-11-16 09:23:07.145000-08:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.list_models().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [DELETE FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS WHERE ID='4a0ec9baec7d11...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [DROP STAGE DASH_DB.DASH_SCHEMA.SNOWML_MODEL_4A0EC9BAEC7D11EE95B1369145349CE2]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA ( ATTRIBUTE_NAME,EVENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    }
   ],
   "source": [
    "registry.delete_model(model_name=MODEL_NAME,model_version='BaseV1.1',delete_artifact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT  *  FROM (SELECT * FROM DASH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE STAGE DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:absl:Model signatures are auto inferred as:\n",
      "\n",
      "{'infer': ModelSignature(\n",
      "                    inputs=[\n",
      "                        FeatureSpec(dtype=DataType.STRING, name='input')\n",
      "                    ],\n",
      "                    outputs=[\n",
      "                        FeatureSpec(dtype=DataType.STRING, name='generated_text')\n",
      "                    ]\n",
      "                )}\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpytpq0mqd/model.zip' '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpytpq0mqd/MANIFEST.yml' '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D9...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpytpq0mqd/runtimes/python_runtime/env/conda.yml' '@DASH_DB.DA...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpytpq0mqd/runtimes/python_runtime/env/requirements.txt' '@DAS...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpytpq0mqd/functions/infer.py' '@DASH_DB.DASH_SCHEMA.SNOWML_MO...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT  *  FROM (SELECT * FROM DASH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS ( CREATION_ENVIRONMENT_S...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA ( ATTRIBUTE_NAME,EVENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    }
   ],
   "source": [
    "llama_model_ref = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model,\n",
    "    conda_dependencies=['sentencepiece']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if the model is already deployed, you may reference it using Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llama_model_ref = model_registry.ModelReference(\n",
    "#     registry=registry, \n",
    "#     model_name=MODEL_NAME, \n",
    "#     model_version=MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: Deploying model for the first time can take ~25-30mins*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE STAGE IF NOT EXISTS DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS_STAG...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [LIST @DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [ls @DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2/MANIFEST...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2/function...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2/model.zi...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2/runtimes...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2/runtimes...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SHOW PARAMETERS LIKE 'PYTHON_CONNECTOR_QUERY_RESULT_FORMAT' IN SESSION]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy_options:num_workers has been defaulted to 1 when using GPU.\n",
      "WARNING:snowflake.ml.model._deploy_client.snowservice.deploy:Building the Docker image and deploying to Snowpark Container Service. This process may take anywhere from a few minutes to a longer period for GPU-based models.\n",
      "INFO:snowflake.ml.model._deploy_client.image_builds.server_image_builder:Starting server-side image build\n",
      "WARNING:snowflake.ml.model._deploy_client.utils.snowservice_client:Best-effort log streaming from SPCS will be enabled when python logging level is set to INFO.Alternatively, you can also query the logs by running the query 'CALL SYSTEM$GET_JOB_LOGS('01b346db-0002-42e7-0040-1e87002331de', 'kaniko')'\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Starting Kaniko command...\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Monitoring session token changes in the background...\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:51Z] Resolved base name mambaorg/micromamba:1.4.3 to build \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:51Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:51Z] Retrieving image mambaorg/micromamba:1.4.3 from registry index.docker.io \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Returning cached image manifest              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Built cross stage deps: map[]                \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Returning cached image manifest              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Retrieving image manifest mambaorg/micromamba:1.4.3 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Returning cached image manifest              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Executing 0 build triggers                   \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Building stage 'mambaorg/micromamba:1.4.3' [idx: '0', base-idx: '-1'] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Checking for cached layer sfsenorthamerica-build-spcs.registry.snowflakecomputing.com/dash_db/dash_schema/snowml_repo/cache:d590c711a93eaf8f99bb4adf06cb9e0c63fb805ea3618c52289bbcbe95870dc6... \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] No cached layer found for cmd RUN --mount=type=cache,target=/opt/conda/pkgs CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Cmd: USER                                    \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Cmd: USER                                    \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Cmd: EXPOSE                                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Adding exposed port: 5000/tcp                \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:52Z] Unpacking rootfs as cmd COPY env/conda.yml conda.yml requires it. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:55Z] Initializing snapshotter ...                 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:55Z] Taking snapshot of full filesystem...        \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] COPY env/conda.yml conda.yml                 \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] Taking snapshot of files...                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] COPY env/requirements.txt requirements.txt   \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] Taking snapshot of files...                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] ARG MAMBA_DOCKERFILE_ACTIVATE=1              \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] ENV CONDA_PREFIX=/opt/conda                  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] No files changed in this command, skipping snapshotting. \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] RUN --mount=type=cache,target=/opt/conda/pkgs CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] Cmd: /usr/local/bin/_dockerfile_shell.sh     \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] Args: [CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] Util.Lookup returned: &{Uid:1000 Gid:1000 Username:mambauser Name: HomeDir:/home/mambauser} \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] Performing slow lookup of group ids for mambauser \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\u001b[36mINFO\u001b[0m[2024-03-27T22:19:56Z] Running: [/usr/local/bin/_dockerfile_shell.sh CONDA_OVERRIDE_CUDA=\"11.7\"     micromamba install -y -n base -f conda.yml && \tpython -m pip install \"uvicorn[standard]\" gunicorn starlette==0.30.0 && \tpython -m pip install -r requirements.txt &&     micromamba clean -afy] \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:                                           __\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:          __  ______ ___  ____ _____ ___  / /_  ____ _\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:         / / / / __ `__ \\/ __ `/ __ `__ \\/ __ \\/ __ `/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:       / .___/_/ /_/ /_/\\__,_/_/ /_/ /_/_.___/\\__,_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      /_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Transaction\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Prefix: /opt/conda\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Updating specs:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - python=3.10\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - sentencepiece\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - absl-py==1.3.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - anyio==3.7.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - cloudpickle==2.2.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - numpy==1.24.3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - packaging==23.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pandas==1.5.3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pyyaml==6.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - snowflake-snowpark-python==1.12.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - typing-extensions==4.6.3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - snowflake-ml-python==1.2.3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - protobuf==4.21.12\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - transformers==4.34.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pyarrow\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - scipy[version='>=1.9']\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - conda-forge::accelerate[version='>=0.22.0']\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - nvidia::cuda=11.7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pytorch::pytorch==2.0.1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   - pytorch::pytorch-cuda=11.7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Package                                Version  Build                         Channel             Size\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:──────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Install:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:──────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + _libgcc_mutex                            0.1  conda_forge                   conda-forge          3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + _openmp_mutex                            4.5  2_gnu                         conda-forge         24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + _py-xgboost-mutex                        2.0  cpu_0                         pkgs/snowflake       9kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + absl-py                                1.3.0  py310h06a4308_0               pkgs/snowflake     173kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + accelerate                            0.28.0  pyhd8ed1ab_0                  conda-forge        193kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aiobotocore                            2.7.0  py310h06a4308_0               pkgs/snowflake     107kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aiohttp                                3.9.3  py310h5eee18b_0               pkgs/snowflake     740kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aioitertools                           0.7.1  pyhd3eb1b0_0                  pkgs/snowflake      20kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aiosignal                              1.2.0  pyhd3eb1b0_0                  pkgs/snowflake      13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + anyio                                  3.7.0  pyhd8ed1ab_1                  conda-forge         97kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + arrow-cpp                             11.0.0  h58bb7b3_33_cpu               conda-forge         38kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + asn1crypto                             1.5.1  py310h06a4308_0               pkgs/snowflake     169kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + async-timeout                          4.0.3  py310h06a4308_0               pkgs/snowflake      12kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + attrs                                 23.1.0  py310h06a4308_0               pkgs/snowflake     133kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-auth                             0.7.3  h28f7589_1                    conda-forge        102kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-cal                              0.6.1  hc309b26_1                    conda-forge         51kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-common                           0.9.0  hd590300_0                    conda-forge        198kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-compression                     0.2.17  h4d4d85c_2                    conda-forge         19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-event-stream                     0.3.1  h2e3709c_4                    conda-forge         54kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-http                            0.7.11  h00aa349_4                    conda-forge        194kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-io                             0.13.32  he9a53bd_1                    conda-forge        155kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-mqtt                             0.9.3  hb447be9_1                    conda-forge        162kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-s3                              0.3.14  hf3aad02_1                    conda-forge         87kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-c-sdkutils                        0.1.12  h4d4d85c_1                    conda-forge         53kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-checksums                         0.1.17  h4d4d85c_1                    conda-forge         50kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-crt-cpp                           0.21.0  hb942446_5                    conda-forge        320kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + aws-sdk-cpp                          1.10.57  h85b1a90_19                   conda-forge          4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + blas                                     1.0  mkl                           pkgs/snowflake       6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + boost-cpp                             1.82.0  hdb19cb5_2                    pkgs/snowflake      11kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + botocore                             1.31.64  py310h06a4308_0               pkgs/snowflake       7MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + bottleneck                             1.3.7  py310ha9d4c09_0               pkgs/snowflake     129kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + brotli-python                          1.0.9  py310h6a678d5_7               pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + bzip2                                  1.0.8  h5eee18b_5                    pkgs/snowflake     427kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + c-ares                                1.19.1  h5eee18b_0                    pkgs/snowflake     116kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + ca-certificates                    2024.3.11  h06a4308_0                    pkgs/snowflake     137kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cachetools                             4.2.2  pyhd3eb1b0_0                  pkgs/snowflake      13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + certifi                             2024.2.2  py310h06a4308_0               pkgs/snowflake     165kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cffi                                  1.16.0  py310h5eee18b_0               pkgs/snowflake     242kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + charset-normalizer                     2.0.4  pyhd3eb1b0_0                  pkgs/snowflake      34kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + click                                  8.1.7  py310h06a4308_0               pkgs/snowflake     155kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cloudpickle                            2.2.1  py310h06a4308_0               pkgs/snowflake      41kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cryptography                          41.0.7  py310hdda0065_0               pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda                                  11.7.1  0                             nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cccl                            12.4.99  0                             nvidia               1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-command-line-tools               11.7.1  0                             nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-compiler                         12.4.0  0                             nvidia               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cudart                          11.7.99  0                             nvidia             199kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cudart-dev                      11.7.99  0                             nvidia               1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cuobjdump                       12.4.99  0                             nvidia             308kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cupti                          11.7.101  0                             nvidia              24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-cuxxfilt                        12.4.99  0                             nvidia             292kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-demo-suite                      12.4.99  0                             nvidia               5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-documentation                   12.4.99  0                             nvidia              92kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-driver-dev                      12.4.99  0                             nvidia              19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-gdb                             12.4.99  0                             nvidia               6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-libraries                        11.7.1  0                             nvidia               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-libraries-dev                    11.7.1  0                             nvidia               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-memcheck                        11.8.86  0                             nvidia             172kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nsight                          12.4.99  0                             nvidia             119MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nsight-compute                   12.4.0  0                             nvidia               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvcc                            12.4.99  0                             nvidia              66MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvdisasm                        12.4.99  0                             nvidia              50MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvml-dev                        12.4.99  0                             nvidia             178kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvprof                          12.4.99  0                             nvidia               5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvprune                         12.4.99  0                             nvidia              67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvrtc                           11.7.99  0                             nvidia              18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvrtc-dev                       11.7.99  0                             nvidia              18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvtx                            11.7.91  0                             nvidia              58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-nvvp                            12.4.99  0                             nvidia             120MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-runtime                          11.7.1  0                             nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-sanitizer-api                   12.4.99  0                             nvidia              18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-toolkit                          11.7.1  0                             nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-tools                            11.7.1  0                             nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + cuda-visual-tools                     11.7.1  0                             nvidia               1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + dataclasses                              0.8  pyh6d0b6a4_7                  pkgs/snowflake       7kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + datasets                              2.12.0  py310h06a4308_0               pkgs/snowflake     719kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + dill                                   0.3.6  py310h06a4308_0               pkgs/snowflake     161kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + exceptiongroup                         1.2.0  py310h06a4308_0               pkgs/snowflake      30kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + filelock                              3.13.1  py310h06a4308_0               pkgs/snowflake      21kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + frozenlist                             1.4.0  py310h5eee18b_0               pkgs/snowflake      57kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + fsspec                             2023.10.0  py310h06a4308_0               pkgs/snowflake     263kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gds-tools                           1.9.0.20  0                             nvidia              43MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gflags                                 2.2.2  h6a678d5_1                    pkgs/snowflake     203kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + glog                                   0.6.0  h6f12383_0                    conda-forge        114kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gmp                                    6.2.1  h295c915_3                    pkgs/snowflake     822kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + gmpy2                                  2.1.2  py310heeb90bb_0               pkgs/snowflake     656kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + huggingface_hub                       0.17.3  py310h06a4308_0               pkgs/snowflake     421kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + icu                                     73.1  h6a678d5_0                    pkgs/snowflake      29MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + idna                                     3.4  py310h06a4308_0               pkgs/snowflake     116kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + importlib-metadata                     7.0.1  py310h06a4308_0               pkgs/snowflake      42kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + importlib_metadata                     7.0.1  hd3eb1b0_0                    pkgs/snowflake       8kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + importlib_resources                    5.2.0  pyhd3eb1b0_1                  pkgs/snowflake      21kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + intel-openmp                        2023.1.0  hdb19cb5_46306                pkgs/snowflake      19MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + jinja2                                 3.1.3  py310h06a4308_0               pkgs/snowflake     276kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + jmespath                               1.0.1  py310h06a4308_0               pkgs/snowflake      37kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + joblib                                 1.2.0  py310h06a4308_0               pkgs/snowflake     408kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + krb5                                  1.20.1  h143b758_1                    pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + ld_impl_linux-64                        2.38  h1181459_1                    pkgs/snowflake     749kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libabseil                         20230125.3  cxx17_h59595ed_0              conda-forge          1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libarrow                              11.0.0  hb87d912_33_cpu               conda-forge         27MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libboost                              1.82.0  h109eef0_2                    pkgs/snowflake      24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libbrotlicommon                        1.0.9  h5eee18b_7                    pkgs/snowflake      67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libbrotlidec                           1.0.9  h5eee18b_7                    pkgs/snowflake      35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libbrotlienc                           1.0.9  h5eee18b_7                    pkgs/snowflake     295kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcrc32c                              1.1.2  h6a678d5_0                    pkgs/snowflake      22kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcublas                         11.10.3.66  0                             nvidia             300MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcublas-dev                     11.10.3.66  0                             nvidia             311MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufft                          10.7.2.124  h4fbf590_0                    nvidia              98MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufft-dev                      10.7.2.124  h98a8f43_0                    nvidia             207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufile                           1.9.0.20  0                             nvidia               1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcufile-dev                       1.9.0.20  0                             nvidia              15kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcurand                         10.3.5.119  0                             nvidia              54MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcurand-dev                     10.3.5.119  0                             nvidia             460kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcurl                                8.5.0  h251f7ec_0                    pkgs/snowflake     404kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusolver                         11.4.0.1  0                             nvidia              83MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusolver-dev                     11.4.0.1  0                             nvidia              59MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusparse                        11.7.4.91  0                             nvidia             158MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libcusparse-dev                    11.7.4.91  0                             nvidia             325MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libedit                         3.1.20230828  h5eee18b_0                    pkgs/snowflake     196kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libev                                   4.33  h7f8727e_1                    pkgs/snowflake     109kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libevent                              2.1.12  hdbd6064_1                    pkgs/snowflake     480kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libffi                                 3.4.4  h6a678d5_0                    pkgs/snowflake     148kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgcc-ng                             13.2.0  h807b86a_5                    conda-forge        771kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgfortran-ng                        11.2.0  h00389a5_1                    pkgs/snowflake      20kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgfortran5                          11.2.0  h1234567_1                    pkgs/snowflake       5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgomp                               13.2.0  h807b86a_5                    conda-forge        420kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgoogle-cloud                       2.12.0  hac9eb74_1                    conda-forge         46MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libgrpc                               1.54.3  hb20ce57_0                    conda-forge          6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnghttp2                            1.57.0  h2d74bed_0                    pkgs/snowflake     722kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnpp                             11.7.4.75  0                             nvidia             136MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnpp-dev                         11.7.4.75  0                             nvidia             133MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnuma                               2.0.18  hd590300_0                    conda-forge         43kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnvjpeg                           11.8.0.2  0                             nvidia               2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libnvjpeg-dev                       11.8.0.2  0                             nvidia               2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libprotobuf                          3.21.12  hfc55251_2                    conda-forge          2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libssh2                               1.10.0  hdbd6064_2                    pkgs/snowflake     311kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libstdcxx-ng                          13.2.0  h7e041cc_5                    conda-forge          4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libthrift                             0.18.1  h8fd135c_2                    conda-forge          4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libutf8proc                            2.8.0  h166bdaf_0                    conda-forge        101kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libuuid                               1.41.5  h5eee18b_0                    pkgs/snowflake      29kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libxgboost                             1.7.3  h6a678d5_0                    pkgs/snowflake       4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + libzlib                               1.2.13  hd590300_5                    conda-forge         62kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + lz4-c                                  1.9.4  h6a678d5_0                    pkgs/snowflake     164kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + markupsafe                             2.1.3  py310h5eee18b_0               pkgs/snowflake      24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl                                 2023.1.0  h213fc3f_46344                pkgs/snowflake     207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl-service                            2.4.0  py310h5eee18b_1               pkgs/snowflake      59kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl_fft                                1.3.8  py310h5eee18b_0               pkgs/snowflake     227kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mkl_random                             1.2.4  py310hdb19cb5_0               pkgs/snowflake     329kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mpc                                    1.1.0  h10f8cd9_1                    pkgs/snowflake      96kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mpfr                                   4.0.2  hb69a4c5_1                    pkgs/snowflake     669kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + mpmath                                 1.3.0  py310h06a4308_0               pkgs/snowflake     998kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + multidict                              6.0.4  py310h5eee18b_0               pkgs/snowflake      58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + multiprocess                         0.70.14  py310h06a4308_0               pkgs/snowflake     228kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + ncurses                                  6.4  h6a678d5_0                    pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + networkx                                 3.1  py310h06a4308_0               pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + nsight-compute                   2024.1.0.13  0                             nvidia             699MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + numexpr                                2.8.7  py310h85018f9_0               pkgs/snowflake     142kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + numpy                                 1.24.3  py310h5f9d8c6_1               pkgs/snowflake      10kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + numpy-base                            1.24.3  py310hb5e798b_1               pkgs/snowflake       8MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + openssl                                3.2.1  hd590300_1                    conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + orc                                    1.9.0  h2f23424_1                    conda-forge          1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + packaging                               23.1  py310h06a4308_0               pkgs/snowflake      73kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pandas                                 1.5.3  py310h1128e8f_0               pkgs/snowflake      14MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pip                                   23.3.1  py310h06a4308_0               pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + platformdirs                          3.10.0  py310h06a4308_0               pkgs/snowflake      32kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + protobuf                             4.21.12  py310heca2aa9_0               conda-forge        324kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + psutil                                 5.9.0  py310h5eee18b_0               pkgs/snowflake     394kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + py-xgboost                             1.7.3  py310h06a4308_0               pkgs/snowflake     204kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyarrow                               11.0.0  py310h468efa6_1               pkgs/snowflake       5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pycparser                               2.21  pyhd3eb1b0_0                  pkgs/snowflake      97kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyjwt                                  2.4.0  py310h06a4308_0               pkgs/snowflake      35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyopenssl                             23.2.0  py310h06a4308_0               pkgs/snowflake      95kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pysocks                                1.7.1  py310h06a4308_0               pkgs/snowflake      28kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python                               3.10.13  h955ad1f_0                    pkgs/snowflake      29MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python-dateutil             2.8.3+snowflake1  py310h06a4308_1               pkgs/snowflake     326kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python-xxhash                          2.0.2  py310h5eee18b_1               pkgs/snowflake      22kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + python_abi                              3.10  2_cp310                       conda-forge          4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytimeparse                            1.1.8  py310h06a4308_0               pkgs/snowflake      17kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytorch                                2.0.1  py3.10_cuda11.7_cudnn8.5.0_0  pytorch              1GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytorch-cuda                            11.7  h778d358_5                    pytorch              4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytorch-mutex                            1.0  cuda                          pytorch              3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pytz                            2023.3.post1  py310h06a4308_0               pkgs/snowflake     260kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + pyyaml                                   6.0  py310h5eee18b_1               pkgs/snowflake     176kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + rdma-core                               28.9  h59595ed_1                    conda-forge          4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + re2                               2023.03.02  h8c504da_0                    conda-forge        201kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + readline                                 8.2  h5eee18b_0                    pkgs/snowflake     468kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + regex                              2023.10.3  py310h5eee18b_0               pkgs/snowflake     398kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + requests                              2.31.0  py310h06a4308_1               pkgs/snowflake      95kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + responses                             0.13.3  pyhd3eb1b0_0                  pkgs/snowflake      25kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + retrying                               1.3.3  pyhd3eb1b0_2                  pkgs/snowflake      15kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + s2n                                   1.3.49  h06160fa_0                    conda-forge        371kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + s3fs                               2023.10.0  py310h06a4308_0               pkgs/snowflake      55kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sacremoses                            0.0.43  pyhd3eb1b0_0                  pkgs/snowflake     452kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + safetensors                            0.4.2  py310ha89cbab_0               pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + scikit-learn                           1.3.0  py310h1128e8f_1               pkgs/snowflake      11MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + scipy                                 1.11.4  py310h5f9d8c6_0               pkgs/snowflake      24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sentencepiece                         0.1.99  py310hdb19cb5_0               pkgs/snowflake       9MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + setuptools                            68.2.2  py310h06a4308_0               pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + six                                   1.16.0  pyhd3eb1b0_1                  pkgs/snowflake      19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + snappy                                1.1.10  h6a678d5_1                    pkgs/snowflake      49kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sniffio                                1.3.0  py310h06a4308_0               pkgs/snowflake      17kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + snowflake-connector-python             3.7.0  py310h6a678d5_0               pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + snowflake-ml-python                    1.2.3  py310h5eee18b_0               pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + snowflake-snowpark-python             1.12.0  py310h06a4308_0               pkgs/snowflake     635kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sortedcontainers                       2.4.0  pyhd3eb1b0_0                  pkgs/snowflake      27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sqlite                                3.41.2  h5eee18b_0                    pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sqlparse                               0.4.4  py310h06a4308_0               pkgs/snowflake      70kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + sympy                                   1.12  py310h06a4308_0               pkgs/snowflake      11MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tbb                                 2021.8.0  hdb19cb5_0                    pkgs/snowflake       2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + threadpoolctl                          2.2.0  pyh0d69192_0                  pkgs/snowflake      16kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tk                                    8.6.12  h1ccaba5_0                    pkgs/snowflake       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tokenizers                            0.14.1  py310h320607d_2               conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tomlkit                               0.11.1  py310h06a4308_0               pkgs/snowflake      72kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + torchtriton                            2.0.0  py310                         pytorch             66MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tqdm                                  4.65.0  py310h2f386ee_0               pkgs/snowflake     125kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + transformers                          4.34.0  pyhd8ed1ab_0                  conda-forge          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + typing-extensions                      4.6.3  py310h06a4308_0               pkgs/snowflake       9kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + typing_extensions                      4.6.3  py310h06a4308_0               pkgs/snowflake      56kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + tzdata                                 2024a  h04d1e81_0                    pkgs/snowflake     125kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + ucx                                   1.14.1  h64cca9d_5                    conda-forge         15MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + urllib3                                2.0.7  py310h06a4308_0               pkgs/snowflake     171kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + wheel                                 0.41.2  py310h06a4308_0               pkgs/snowflake     102kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + wrapt                                 1.14.1  py310h5eee18b_0               pkgs/snowflake      89kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + xgboost                                1.7.3  py310h06a4308_0               pkgs/snowflake      11kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + xxhash                                 0.8.0  h7f8727e_3                    pkgs/snowflake      93kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + xz                                     5.4.6  h5eee18b_0                    pkgs/snowflake     778kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + yaml                                   0.2.5  h7b6447c_0                    pkgs/snowflake      89kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + yarl                                   1.9.3  py310h5eee18b_0               pkgs/snowflake     117kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + zipp                                  3.17.0  py310h06a4308_0               pkgs/snowflake      21kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + zlib                                  1.2.13  hd590300_5                    conda-forge         93kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  + zstd                                   1.5.5  hc292b87_0                    pkgs/snowflake       1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Summary:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Install: 231 packages\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Total download: 5GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:──────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Transaction starting\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-demo-suite-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cudart-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cupti-11.7.101-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-cupti-11.7.101-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvrtc-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvtx-11.7.91-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvtx-11.7.91-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcublas-11.10.3.66-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufft-10.7.2.124-h4fbf590_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusolver-11.4.0.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusparse-11.7.4.91-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnpp-11.7.4.75-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnvjpeg-11.8.0.2-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nsight-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nsight-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvml-dev-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvml-dev-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking nsight-compute-2024.1.0.13-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [nsight-compute-2024.1.0.13-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufile-1.9.0.20-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cuobjdump-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-cuobjdump-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cuxxfilt-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-cuxxfilt-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvcc-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvcc-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvprune-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvprune-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-documentation-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-documentation-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvdisasm-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvdisasm-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvprof-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvprof-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cccl-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-driver-dev-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcurand-10.3.5.119-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-gdb-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-sanitizer-api-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-sanitizer-api-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-memcheck-11.8.86-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-memcheck-11.8.86-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvrtc-dev-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcublas-dev-11.10.3.66-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufft-dev-10.7.2.124-h98a8f43_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusolver-dev-11.4.0.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcusparse-dev-11.7.4.91-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [libcusparse-dev-11.7.4.91-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - lib/libcusparse.so.11\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - lib/libcusparse.so.11.7.4.91\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnpp-dev-11.7.4.75-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnvjpeg-dev-11.8.0.2-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nsight-compute-12.4.0-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcufile-dev-1.9.0.20-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gds-tools-1.9.0.20-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-compiler-12.4.0-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-nvvp-12.4.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:warning  libmamba [cuda-nvvp-12.4.99-0] The following files were already present in the environment:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    - LICENSE\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-cudart-dev-11.7.99-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcurand-dev-10.3.5.119-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-libraries-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-command-line-tools-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-libraries-dev-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-runtime-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-visual-tools-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-tools-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-toolkit-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cuda-11.7.1-0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking _libgcc_mutex-0.1-conda_forge\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libstdcxx-ng-13.2.0-h7e041cc_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgomp-13.2.0-h807b86a_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking _openmp_mutex-4.5-2_gnu\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgcc-ng-13.2.0-h807b86a_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking rdma-core-28.9-h59595ed_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnuma-2.0.18-hd590300_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-common-0.9.0-hd590300_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking re2-2023.03.02-h8c504da_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libabseil-20230125.3-cxx17_h59595ed_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libutf8proc-2.8.0-h166bdaf_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libzlib-1.2.13-hd590300_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking ucx-1.14.1-h64cca9d_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-compression-0.2.17-h4d4d85c_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-checksums-0.1.17-h4d4d85c_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-sdkutils-0.1.12-h4d4d85c_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking zlib-1.2.13-hd590300_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libprotobuf-3.21.12-hfc55251_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking ca-certificates-2024.3.11-h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking blas-1.0-mkl\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgfortran5-11.2.0-h1234567_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking ld_impl_linux-64-2.38-h1181459_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking _py-xgboost-mutex-2.0-cpu_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libxgboost-1.7.3-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcrc32c-1.1.2-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libev-4.33-h7f8727e_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking snappy-1.1.10-h6a678d5_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libbrotlicommon-1.0.9-h5eee18b_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking c-ares-1.19.1-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking xxhash-0.8.0-h7f8727e_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking lz4-c-1.9.4-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gmp-6.2.1-h295c915_3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking icu-73.1-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tbb-2021.8.0-hdb19cb5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gflags-2.2.2-h6a678d5_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking xz-5.4.6-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking ncurses-6.4-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libffi-3.4.4-h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking bzip2-1.0.8-h5eee18b_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking yaml-0.2.5-h7b6447c_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libuuid-1.41.5-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tk-8.6.12-h1ccaba5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgfortran-ng-11.2.0-h00389a5_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libbrotlienc-1.0.9-h5eee18b_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libbrotlidec-1.0.9-h5eee18b_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mpfr-4.0.2-hb69a4c5_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking zstd-1.5.5-hc292b87_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libedit-3.1.20230828-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking readline-8.2-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking intel-openmp-2023.1.0-hdb19cb5_46306\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mpc-1.1.0-h10f8cd9_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libboost-1.82.0-h109eef0_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sqlite-3.41.2-h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl-2023.1.0-h213fc3f_46344\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking boost-cpp-1.82.0-hdb19cb5_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tzdata-2024a-h04d1e81_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pytorch-cuda-11.7-h778d358_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking openssl-3.2.1-hd590300_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking glog-0.6.0-h6f12383_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking orc-1.9.0-h2f23424_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking s2n-1.3.49-h06160fa_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-cal-0.6.1-hc309b26_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgrpc-1.54.3-hb20ce57_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-http-0.7.11-h00aa349_4\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-event-stream-0.3.1-h2e3709c_4\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-mqtt-0.9.3-hb447be9_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-auth-0.7.3-h28f7589_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-c-s3-0.3.14-hf3aad02_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-crt-cpp-0.21.0-hb942446_5\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libevent-2.1.12-hdbd6064_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libssh2-1.10.0-hdbd6064_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking krb5-1.20.1-h143b758_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libnghttp2-1.57.0-h2d74bed_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python-3.10.13-h955ad1f_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking wheel-0.41.2-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libcurl-8.5.0-h251f7ec_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking setuptools-68.2.2-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pip-23.3.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking jmespath-1.0.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pysocks-1.7.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking brotli-python-1.0.9-py310h6a678d5_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking wrapt-1.14.1-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking multidict-6.0.4-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking frozenlist-1.4.0-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking attrs-23.1.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking async-timeout-4.0.3-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python-xxhash-2.0.2-py310h5eee18b_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking dill-0.3.6-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking zipp-3.17.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking markupsafe-2.1.3-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tomlkit-0.11.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pytz-2023.3.post1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyjwt-2.4.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking platformdirs-3.10.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking certifi-2024.2.2-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking asn1crypto-1.5.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sqlparse-0.4.4-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pytimeparse-1.1.8-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking fsspec-2023.10.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mpmath-1.3.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking gmpy2-2.1.2-py310heeb90bb_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking joblib-1.2.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking click-8.1.7-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking networkx-3.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl-service-2.4.0-py310h5eee18b_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking psutil-5.9.0-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sniffio-1.3.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking idna-3.4-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking exceptiongroup-1.2.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tqdm-4.65.0-py310h2f386ee_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking safetensors-0.4.2-py310ha89cbab_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking regex-2023.10.3-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking filelock-3.13.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking typing_extensions-4.6.3-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyyaml-6.0-py310h5eee18b_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking packaging-23.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cloudpickle-2.2.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking absl-py-1.3.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sentencepiece-0.1.99-py310hdb19cb5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking urllib3-2.0.7-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking multiprocess-0.70.14-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking importlib-metadata-7.0.1-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking jinja2-3.1.3-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sympy-1.12-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking numpy-base-1.24.3-py310hb5e798b_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking yarl-1.9.3-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking typing-extensions-4.6.3-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking numpy-1.24.3-py310h5f9d8c6_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl_fft-1.3.8-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking mkl_random-1.2.4-py310hdb19cb5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking numexpr-2.8.7-py310h85018f9_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking bottleneck-1.3.7-py310ha9d4c09_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking scipy-1.11.4-py310h5f9d8c6_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libthrift-0.18.1-h8fd135c_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libgoogle-cloud-2.12.0-hac9eb74_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aws-sdk-cpp-1.10.57-h85b1a90_19\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python_abi-3.10-2_cp310\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking libarrow-11.0.0-hb87d912_33_cpu\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking protobuf-4.21.12-py310heca2aa9_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking arrow-cpp-11.0.0-h58bb7b3_33_cpu\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking threadpoolctl-2.2.0-pyh0d69192_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pycparser-2.21-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sortedcontainers-2.4.0-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cachetools-4.2.2-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking six-1.16.0-pyhd3eb1b0_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking dataclasses-0.8-pyh6d0b6a4_7\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aiosignal-1.2.0-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking importlib_resources-5.2.0-pyhd3eb1b0_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aioitertools-0.7.1-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking importlib_metadata-7.0.1-hd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking retrying-1.3.3-pyhd3eb1b0_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking sacremoses-0.0.43-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking anyio-3.7.0-pyhd8ed1ab_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pytorch-2.0.1-py3.10_cuda11.7_cudnn8.5.0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking torchtriton-2.0.0-py310\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyarrow-11.0.0-py310h468efa6_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking scikit-learn-1.3.0-py310h1128e8f_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cffi-1.16.0-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking requests-2.31.0-py310h06a4308_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking python-dateutil-2.8.3+snowflake1-py310h06a4308_1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aiohttp-3.9.3-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking py-xgboost-1.7.3-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking cryptography-41.0.7-py310hdda0065_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking huggingface_hub-0.17.3-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking botocore-1.31.64-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pandas-1.5.3-py310h1128e8f_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking xgboost-1.7.3-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking pyopenssl-23.2.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking aiobotocore-2.7.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking snowflake-connector-python-3.7.0-py310h6a678d5_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking s3fs-2023.10.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking snowflake-snowpark-python-1.12.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking snowflake-ml-python-1.2.3-py310h5eee18b_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking responses-0.13.3-pyhd3eb1b0_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking tokenizers-0.14.1-py310h320607d_2\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking accelerate-0.28.0-pyhd8ed1ab_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking datasets-2.12.0-py310h06a4308_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Linking transformers-4.34.0-pyhd8ed1ab_0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Transaction finished\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:To activate this environment, use:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    micromamba activate base\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Or to execute a single command in this environment, use:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    micromamba run -n base mycommand\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting gunicorn\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting starlette==0.30.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading starlette-0.30.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting uvicorn[standard]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette==0.30.0) (3.7.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]) (8.1.7)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting h11>=0.8 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: typing-extensions>=4.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]) (4.6.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting httptools>=0.5.0 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting python-dotenv>=0.13 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]) (6.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting websockets>=10.4 (from uvicorn[standard])\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gunicorn) (23.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.30.0) (3.4)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.30.0) (1.3.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.30.0) (1.2.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading starlette-0.30.0-py3-none-any.whl (68 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 68.8/68.8 kB 5.7 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.2/80.2 kB 6.1 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 5.1 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.4/341.4 kB 25.3 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 67.1 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 70.7 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.2/130.2 kB 10.5 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 5.4 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Installing collected packages: websockets, uvloop, python-dotenv, httptools, h11, gunicorn, watchfiles, uvicorn, starlette\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Successfully installed gunicorn-21.2.0 h11-0.14.0 httptools-0.6.1 python-dotenv-1.0.1 starlette-0.30.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting peft==0.5.0 (from -r requirements.txt (line 1))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting vllm==0.2.1.post1 (from -r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading vllm-0.2.1.post1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.2 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting bitsandbytes>=0.41.0 (from -r requirements.txt (line 3))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (1.24.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (23.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (5.9.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (6.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (4.34.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (4.65.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (0.28.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 1)) (0.4.2)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting ninja (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting ray>=2.5.1 (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.5.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (11.0.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.1.99)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting xformers==0.0.22 (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting fastapi (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: uvicorn[standard] in /opt/conda/lib/python3.10/site-packages (from vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.29.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting pydantic<2 (from vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.2/150.2 kB 7.8 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (3.13.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (4.6.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (1.12)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (3.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (3.1.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (8.1.7)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting jsonschema (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (4.21.12)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.2.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.4.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2.31.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0->-r requirements.txt (line 1)) (0.17.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0->-r requirements.txt (line 1)) (2023.10.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0->-r requirements.txt (line 1)) (0.14.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting starlette<0.37.0,>=0.36.3 (from fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting typing-extensions (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2.8.3+snowflake1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.14.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.6.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.0.1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.19.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (0.21.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm==0.2.1.post1->-r requirements.txt (line 2)) (12.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->peft==0.5.0->-r requirements.txt (line 1)) (2023.10.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.16.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.37.0,>=0.36.3->fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2)) (3.7.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (2.1.3)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (23.1.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting referencing>=0.28.4 (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collecting rpds-py>=0.7.1 (from jsonschema->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2))\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Downloading rpds_py-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2.0.4)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (3.4)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2.0.7)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray>=2.5.1->vllm==0.2.1.post1->-r requirements.txt (line 2)) (2024.2.2)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.3.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi->vllm==0.2.1.post1->-r requirements.txt (line 2)) (1.2.0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 8.6 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading vllm-0.2.1.post1-cp310-cp310-manylinux1_x86_64.whl (28.6 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.6/28.6 MB 36.0 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl (211.6 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.6/211.6 MB 13.2 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Downloading rpds_py-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 72.7 MB/s eta 0:00:00\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Installing collected packages: ninja, typing-extensions, rpds-py, msgpack, starlette, referencing, pydantic, xformers, jsonschema-specifications, fastapi, bitsandbytes, jsonschema, ray, peft, vllm\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Attempting uninstall: typing-extensions\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Found existing installation: typing_extensions 4.6.3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Uninstalling typing_extensions-4.6.3:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      Successfully uninstalled typing_extensions-4.6.3\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Attempting uninstall: starlette\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Found existing installation: starlette 0.30.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:    Uninstalling starlette-0.30.0:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      Successfully uninstalled starlette-0.30.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:triton 2.0.0 requires cmake, which is not installed.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:triton 2.0.0 requires lit, which is not installed.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Successfully installed bitsandbytes-0.43.0 fastapi-0.110.0 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 msgpack-1.0.8 ninja-1.11.1.1 peft-0.5.0 pydantic-1.10.14 ray-2.10.0 referencing-0.34.0 rpds-py-0.18.0 starlette-0.36.3 typing-extensions-4.10.0 vllm-0.2.1.post1 xformers-0.0.22\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:                                           __\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:          __  ______ ___  ____ _____ ___  / /_  ____ _\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:         / / / / __ `__ \\/ __ `/ __ `__ \\/ __ \\/ __ `/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:       / .___/_/ /_/ /_/\\__,_/_/ /_/ /_/_.___/\\__,_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:      /_/\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Collect information..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning index cache..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning lock files..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Package file                                                 Size\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:─────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  /opt/conda/pkgs\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:─────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  _libgcc_mutex-0.1-conda_forge.tar.bz2                         3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  _openmp_mutex-4.5-2_gnu.tar.bz2                              24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  _py-xgboost-mutex-2.0-cpu_0.tar.bz2                           9kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  absl-py-1.3.0-py310h06a4308_0.tar.bz2                       173kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  accelerate-0.28.0-pyhd8ed1ab_0.conda                        193kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aiobotocore-2.7.0-py310h06a4308_0.tar.bz2                   107kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aiohttp-3.9.3-py310h5eee18b_0.tar.bz2                       740kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aioitertools-0.7.1-pyhd3eb1b0_0.tar.bz2                      20kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aiosignal-1.2.0-pyhd3eb1b0_0.tar.bz2                         13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  anyio-3.7.0-pyhd8ed1ab_1.conda                               97kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  arrow-cpp-11.0.0-h58bb7b3_33_cpu.conda                       38kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  asn1crypto-1.5.1-py310h06a4308_0.tar.bz2                    169kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  async-timeout-4.0.3-py310h06a4308_0.tar.bz2                  12kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  attrs-23.1.0-py310h06a4308_0.tar.bz2                        133kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-auth-0.7.3-h28f7589_1.conda                           102kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-cal-0.6.1-hc309b26_1.conda                             51kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-common-0.9.0-hd590300_0.conda                         198kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-compression-0.2.17-h4d4d85c_2.conda                    19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-event-stream-0.3.1-h2e3709c_4.conda                    54kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-http-0.7.11-h00aa349_4.conda                          194kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-io-0.13.32-he9a53bd_1.conda                           155kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-mqtt-0.9.3-hb447be9_1.conda                           162kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-s3-0.3.14-hf3aad02_1.conda                             87kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-c-sdkutils-0.1.12-h4d4d85c_1.conda                       53kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-checksums-0.1.17-h4d4d85c_1.conda                        50kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-crt-cpp-0.21.0-hb942446_5.conda                         320kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  aws-sdk-cpp-1.10.57-h85b1a90_19.conda                         4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  blas-1.0-mkl.tar.bz2                                          6kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  boost-cpp-1.82.0-hdb19cb5_2.tar.bz2                          11kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  botocore-1.31.64-py310h06a4308_0.tar.bz2                      7MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  bottleneck-1.3.7-py310ha9d4c09_0.tar.bz2                    129kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  brotli-python-1.0.9-py310h6a678d5_7.tar.bz2                   2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  bzip2-1.0.8-h5eee18b_5.tar.bz2                              427kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  c-ares-1.19.1-h5eee18b_0.tar.bz2                            116kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  ca-certificates-2024.3.11-h06a4308_0.tar.bz2                137kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cachetools-4.2.2-pyhd3eb1b0_0.tar.bz2                        13kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  certifi-2024.2.2-py310h06a4308_0.tar.bz2                    165kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cffi-1.16.0-py310h5eee18b_0.tar.bz2                         242kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  charset-normalizer-2.0.4-pyhd3eb1b0_0.tar.bz2                34kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  click-8.1.7-py310h06a4308_0.tar.bz2                         155kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cloudpickle-2.2.1-py310h06a4308_0.tar.bz2                    41kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cryptography-41.0.7-py310hdda0065_0.tar.bz2                   2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-11.7.1-0.tar.bz2                                         1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cccl-12.4.99-0.tar.bz2                                   1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-command-line-tools-11.7.1-0.tar.bz2                      1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-compiler-12.4.0-0.tar.bz2                                2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cudart-11.7.99-0.tar.bz2                               199kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cudart-dev-11.7.99-0.tar.bz2                             1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cuobjdump-12.4.99-0.tar.bz2                            308kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cupti-11.7.101-0.tar.bz2                                24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-cuxxfilt-12.4.99-0.tar.bz2                             292kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-demo-suite-12.4.99-0.tar.bz2                             5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-documentation-12.4.99-0.tar.bz2                         92kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-driver-dev-12.4.99-0.tar.bz2                            19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-gdb-12.4.99-0.tar.bz2                                    6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-libraries-11.7.1-0.tar.bz2                               2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-libraries-dev-11.7.1-0.tar.bz2                           2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-memcheck-11.8.86-0.tar.bz2                             172kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nsight-12.4.99-0.tar.bz2                               119MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nsight-compute-12.4.0-0.tar.bz2                          2kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvcc-12.4.99-0.tar.bz2                                  66MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvdisasm-12.4.99-0.tar.bz2                              50MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvml-dev-12.4.99-0.tar.bz2                             178kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvprof-12.4.99-0.tar.bz2                                 5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvprune-12.4.99-0.tar.bz2                               67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvrtc-11.7.99-0.tar.bz2                                 18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvrtc-dev-11.7.99-0.tar.bz2                             18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvtx-11.7.91-0.tar.bz2                                  58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-nvvp-12.4.99-0.tar.bz2                                 120MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-runtime-11.7.1-0.tar.bz2                                 1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-sanitizer-api-12.4.99-0.tar.bz2                         18MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-toolkit-11.7.1-0.tar.bz2                                 1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-tools-11.7.1-0.tar.bz2                                   1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  cuda-visual-tools-11.7.1-0.tar.bz2                            1kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  dataclasses-0.8-pyh6d0b6a4_7.tar.bz2                          7kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  datasets-2.12.0-py310h06a4308_0.tar.bz2                     719kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  dill-0.3.6-py310h06a4308_0.tar.bz2                          161kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  exceptiongroup-1.2.0-py310h06a4308_0.tar.bz2                 30kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  filelock-3.13.1-py310h06a4308_0.tar.bz2                      21kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  frozenlist-1.4.0-py310h5eee18b_0.tar.bz2                     57kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  fsspec-2023.10.0-py310h06a4308_0.tar.bz2                    263kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gds-tools-1.9.0.20-0.tar.bz2                                 43MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gflags-2.2.2-h6a678d5_1.tar.bz2                             203kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  glog-0.6.0-h6f12383_0.tar.bz2                               114kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gmp-6.2.1-h295c915_3.tar.bz2                                822kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  gmpy2-2.1.2-py310heeb90bb_0.tar.bz2                         656kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  huggingface_hub-0.17.3-py310h06a4308_0.tar.bz2              421kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  icu-73.1-h6a678d5_0.tar.bz2                                  29MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  idna-3.4-py310h06a4308_0.tar.bz2                            116kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  importlib-metadata-7.0.1-py310h06a4308_0.tar.bz2             42kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  importlib_metadata-7.0.1-hd3eb1b0_0.tar.bz2                   8kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  importlib_resources-5.2.0-pyhd3eb1b0_1.tar.bz2               21kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  intel-openmp-2023.1.0-hdb19cb5_46306.tar.bz2                 19MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  jinja2-3.1.3-py310h06a4308_0.tar.bz2                        276kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  jmespath-1.0.1-py310h06a4308_0.tar.bz2                       37kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  joblib-1.2.0-py310h06a4308_0.tar.bz2                        408kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  krb5-1.20.1-h143b758_1.tar.bz2                                1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  ld_impl_linux-64-2.38-h1181459_1.tar.bz2                    749kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libabseil-20230125.3-cxx17_h59595ed_0.conda                   1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libarrow-11.0.0-hb87d912_33_cpu.conda                        27MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libboost-1.82.0-h109eef0_2.tar.bz2                           24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libbrotlicommon-1.0.9-h5eee18b_7.tar.bz2                     67kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libbrotlidec-1.0.9-h5eee18b_7.tar.bz2                        35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libbrotlienc-1.0.9-h5eee18b_7.tar.bz2                       295kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcrc32c-1.1.2-h6a678d5_0.tar.bz2                           22kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcublas-11.10.3.66-0.tar.bz2                              300MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcublas-dev-11.10.3.66-0.tar.bz2                          311MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufft-10.7.2.124-h4fbf590_0.tar.bz2                       98MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufft-dev-10.7.2.124-h98a8f43_0.tar.bz2                  207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufile-1.9.0.20-0.tar.bz2                                  1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcufile-dev-1.9.0.20-0.tar.bz2                             15kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcurand-10.3.5.119-0.tar.bz2                               54MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcurand-dev-10.3.5.119-0.tar.bz2                          460kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcurl-8.5.0-h251f7ec_0.tar.bz2                            404kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusolver-11.4.0.1-0.tar.bz2                               83MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusolver-dev-11.4.0.1-0.tar.bz2                           59MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusparse-11.7.4.91-0.tar.bz2                             158MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libcusparse-dev-11.7.4.91-0.tar.bz2                         325MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libedit-3.1.20230828-h5eee18b_0.tar.bz2                     196kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libev-4.33-h7f8727e_1.tar.bz2                               109kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libevent-2.1.12-hdbd6064_1.tar.bz2                          480kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libffi-3.4.4-h6a678d5_0.tar.bz2                             148kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgcc-ng-13.2.0-h807b86a_5.conda                           771kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgfortran-ng-11.2.0-h00389a5_1.tar.bz2                     20kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgfortran5-11.2.0-h1234567_1.tar.bz2                        5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgomp-13.2.0-h807b86a_5.conda                             420kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgoogle-cloud-2.12.0-hac9eb74_1.conda                      46MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libgrpc-1.54.3-hb20ce57_0.conda                               6MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnghttp2-1.57.0-h2d74bed_0.tar.bz2                        722kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnpp-11.7.4.75-0.tar.bz2                                  136MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnpp-dev-11.7.4.75-0.tar.bz2                              133MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnuma-2.0.18-hd590300_0.conda                              43kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnvjpeg-11.8.0.2-0.tar.bz2                                  2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libnvjpeg-dev-11.8.0.2-0.tar.bz2                              2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libprotobuf-3.21.12-hfc55251_2.conda                          2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libssh2-1.10.0-hdbd6064_2.tar.bz2                           311kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libstdcxx-ng-13.2.0-h7e041cc_5.conda                          4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libthrift-0.18.1-h8fd135c_2.conda                             4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libutf8proc-2.8.0-h166bdaf_0.tar.bz2                        101kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libuuid-1.41.5-h5eee18b_0.tar.bz2                            29kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libxgboost-1.7.3-h6a678d5_0.tar.bz2                           4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  libzlib-1.2.13-hd590300_5.conda                              62kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  lz4-c-1.9.4-h6a678d5_0.tar.bz2                              164kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  markupsafe-2.1.3-py310h5eee18b_0.tar.bz2                     24kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl-2023.1.0-h213fc3f_46344.tar.bz2                         207MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl-service-2.4.0-py310h5eee18b_1.tar.bz2                    59kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl_fft-1.3.8-py310h5eee18b_0.tar.bz2                       227kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mkl_random-1.2.4-py310hdb19cb5_0.tar.bz2                    329kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mpc-1.1.0-h10f8cd9_1.tar.bz2                                 96kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mpfr-4.0.2-hb69a4c5_1.tar.bz2                               669kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  mpmath-1.3.0-py310h06a4308_0.tar.bz2                        998kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  multidict-6.0.4-py310h5eee18b_0.tar.bz2                      58kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  multiprocess-0.70.14-py310h06a4308_0.tar.bz2                228kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  ncurses-6.4-h6a678d5_0.tar.bz2                                1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  networkx-3.1-py310h06a4308_0.tar.bz2                          3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  nsight-compute-2024.1.0.13-0.tar.bz2                        699MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  numexpr-2.8.7-py310h85018f9_0.tar.bz2                       142kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  numpy-1.24.3-py310h5f9d8c6_1.tar.bz2                         10kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  numpy-base-1.24.3-py310hb5e798b_1.tar.bz2                     8MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  openssl-3.2.1-hd590300_1.conda                                3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  orc-1.9.0-h2f23424_1.conda                                    1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  packaging-23.1-py310h06a4308_0.tar.bz2                       73kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pandas-1.5.3-py310h1128e8f_0.tar.bz2                         14MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pip-23.3.1-py310h06a4308_0.tar.bz2                            3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  platformdirs-3.10.0-py310h06a4308_0.tar.bz2                  32kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  protobuf-4.21.12-py310heca2aa9_0.conda                      324kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  psutil-5.9.0-py310h5eee18b_0.tar.bz2                        394kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  py-xgboost-1.7.3-py310h06a4308_0.tar.bz2                    204kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyarrow-11.0.0-py310h468efa6_1.tar.bz2                        5MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pycparser-2.21-pyhd3eb1b0_0.tar.bz2                          97kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyjwt-2.4.0-py310h06a4308_0.tar.bz2                          35kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyopenssl-23.2.0-py310h06a4308_0.tar.bz2                     95kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pysocks-1.7.1-py310h06a4308_0.tar.bz2                        28kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python-3.10.13-h955ad1f_0.tar.bz2                            29MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python-dateutil-2.8.3+snowflake1-py310h06a4308_1.tar.bz2    326kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python-xxhash-2.0.2-py310h5eee18b_1.tar.bz2                  22kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  python_abi-3.10-2_cp310.tar.bz2                               4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytimeparse-1.1.8-py310h06a4308_0.tar.bz2                    17kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytorch-2.0.1-py3.10_cuda11.7_cudnn8.5.0_0.tar.bz2            1GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytorch-cuda-11.7-h778d358_5.tar.bz2                          4kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytorch-mutex-1.0-cuda.tar.bz2                                3kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pytz-2023.3.post1-py310h06a4308_0.tar.bz2                   260kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  pyyaml-6.0-py310h5eee18b_1.tar.bz2                          176kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  rdma-core-28.9-h59595ed_1.conda                               4MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  re2-2023.03.02-h8c504da_0.conda                             201kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  readline-8.2-h5eee18b_0.tar.bz2                             468kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  regex-2023.10.3-py310h5eee18b_0.tar.bz2                     398kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  requests-2.31.0-py310h06a4308_1.tar.bz2                      95kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  responses-0.13.3-pyhd3eb1b0_0.tar.bz2                        25kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  retrying-1.3.3-pyhd3eb1b0_2.tar.bz2                          15kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  s2n-1.3.49-h06160fa_0.conda                                 371kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  s3fs-2023.10.0-py310h06a4308_0.tar.bz2                       55kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sacremoses-0.0.43-pyhd3eb1b0_0.tar.bz2                      452kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  safetensors-0.4.2-py310ha89cbab_0.tar.bz2                     1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  scikit-learn-1.3.0-py310h1128e8f_1.tar.bz2                   11MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  scipy-1.11.4-py310h5f9d8c6_0.tar.bz2                         24MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sentencepiece-0.1.99-py310hdb19cb5_0.tar.bz2                  9MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  setuptools-68.2.2-py310h06a4308_0.tar.bz2                     1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  six-1.16.0-pyhd3eb1b0_1.tar.bz2                              19kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  snappy-1.1.10-h6a678d5_1.tar.bz2                             49kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sniffio-1.3.0-py310h06a4308_0.tar.bz2                        17kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  snowflake-connector-python-3.7.0-py310h6a678d5_0.tar.bz2      1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  snowflake-ml-python-1.2.3-py310h5eee18b_0.tar.bz2             2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  snowflake-snowpark-python-1.12.0-py310h06a4308_0.tar.bz2    635kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sortedcontainers-2.4.0-pyhd3eb1b0_0.tar.bz2                  27kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sqlite-3.41.2-h5eee18b_0.tar.bz2                              2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sqlparse-0.4.4-py310h06a4308_0.tar.bz2                       70kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  sympy-1.12-py310h06a4308_0.tar.bz2                           11MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tbb-2021.8.0-hdb19cb5_0.tar.bz2                               2MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  threadpoolctl-2.2.0-pyh0d69192_0.tar.bz2                     16kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tk-8.6.12-h1ccaba5_0.tar.bz2                                  3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tokenizers-0.14.1-py310h320607d_2.conda                       3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tomlkit-0.11.1-py310h06a4308_0.tar.bz2                       72kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  torchtriton-2.0.0-py310.tar.bz2                              66MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tqdm-4.65.0-py310h2f386ee_0.tar.bz2                         125kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  transformers-4.34.0-pyhd8ed1ab_0.conda                        3MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  typing-extensions-4.6.3-py310h06a4308_0.tar.bz2               9kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  typing_extensions-4.6.3-py310h06a4308_0.tar.bz2              56kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  tzdata-2024a-h04d1e81_0.tar.bz2                             125kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  ucx-1.14.1-h64cca9d_5.conda                                  15MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  urllib3-2.0.7-py310h06a4308_0.tar.bz2                       171kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  wheel-0.41.2-py310h06a4308_0.tar.bz2                        102kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  wrapt-1.14.1-py310h5eee18b_0.tar.bz2                         89kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  xgboost-1.7.3-py310h06a4308_0.tar.bz2                        11kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  xxhash-0.8.0-h7f8727e_3.tar.bz2                              93kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  xz-5.4.6-h5eee18b_0.tar.bz2                                 778kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  yaml-0.2.5-h7b6447c_0.tar.bz2                                89kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  yarl-1.9.3-py310h5eee18b_0.tar.bz2                          117kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  zipp-3.17.0-py310h06a4308_0.tar.bz2                          21kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  zlib-1.2.13-hd590300_5.conda                                 93kB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  zstd-1.5.5-hc292b87_0.tar.bz2                                 1MB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  /home/mambauser/.mamba/pkgs\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:─────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  \n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:─────────────────────────────────────────────────────────────────────\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  Total size:                                                   5GB\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning tarballs..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Cleaning packages..\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Time taken to build and upload image to registry: 961.42 seconds\n",
      "WARNING:snowflake.ml.model._deploy_client.snowservice.deploy:Image successfully built! For future model deployments, the image will be reused if possible, saving model deployment time. To enforce using the same image, include 'prebuilt_snowflake_image': 'sfsenorthamerica-build-spcs.registry.snowflakecomputing.com/dash_db/dash_schema/snowml_repo/4d71df997ca151dd6eea84d2f18ad40522ba1171:latest' in the deploy() function's options.\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /v2/dash_db/dash_schema/snowml_repo/4d71df997ca151dd6eea84d2f18ad40522ba1171/manifests/LLAMA2_7b_CHAT\n",
      "INFO:snowflake.ml.model._deploy_client.utils.snowservice_client:Creating service DASH_DB.DASH_SCHEMA.service_d997d326ec8511ee95b1369145349ce2\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Wait for service DASH_DB.DASH_SCHEMA.service_d997d326ec8511ee95b1369145349ce2 to become ready...\n",
      "WARNING:snowflake.ml.model._deploy_client.utils.snowservice_client:Best-effort log streaming from SPCS will be enabled when python logging level is set to INFO.Alternatively, you can also query the logs by running the query 'CALL SYSTEM$GET_SERVICE_LOGS('DASH_DB.DASH_SCHEMA.service_d997d326ec8511ee95b1369145349ce2', '0', 'inference-server')'\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Number of CPU cores: 8\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Setting number of workers to 1\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:58 +0000] [1] [INFO] Starting gunicorn 21.2.0\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:58 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:58 +0000] [1] [INFO] Using worker: uvicorn.workers.UvicornWorker\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:58 +0000] [24] [INFO] Booting worker with pid: 24\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:59 +0000] [24] [INFO] ENV: environ({'SERVICE_SERVICE_HOST': '10.103.116.188', 'NVIDIA_VISIBLE_DEVICES': 'GPU-0ba7d308-f0c6-f488-c1b7-cb9fe7af7de0', 'KUBERNETES_SERVICE_PORT_HTTPS': '443', 'KUBERNETES_SERVICE_PORT': '443', 'ENV_NAME': 'base', 'MAMBA_USER': 'mambauser', 'SERVICE_PORT_5000_TCP_PROTO': 'tcp', 'HOSTNAME': 'statefulset-0', '_CONCURRENT_REQUESTS_MAX': '1', 'stage_uid': '1000', 'NUM_WORKERS': '1', 'SNOWFLAKE_PORT': '443', 'PWD': '/tmp', 'CONDA_PREFIX': '/opt/conda', 'SERVICE_SERVICE_PORT_PREDICT': '5000', 'MAMBA_ROOT_PREFIX': '/opt/conda', 'SNOWFLAKE_ACCOUNT': 'RTB37168', 'SNOWFLAKE_DATABASE': 'DASH_DB', 'TARGET_METHOD': 'infer', 'vol1_gid': '0', 'vol1_uid': '0', 'HOME': '/home/mambauser', 'SERVICE_PORT_5000_TCP_ADDR': '10.103.116.188', 'LANG': 'C.UTF-8', 'KUBERNETES_PORT_443_TCP': 'tcp://10.96.0.1:443', 'CONDA_PROMPT_MODIFIER': '(base) ', 'SNOWML_USE_GPU': 'true', 'SNOWFLAKE_SCHEMA': 'DASH_SCHEMA', 'SERVICE_PORT_5000_TCP': 'tcp://10.103.116.188:5000', 'stage_gid': '1000', 'MAMBA_EXE': '/bin/micromamba', 'SNOWFLAKE_HOST': 'snowflake.prod3.us-west-2.aws.snowflakecomputing.com', 'USER': 'mambauser', 'SERVICE_PORT_5000_TCP_PORT': '5000', 'CONDA_SHLVL': '1', 'SHLVL': '0', 'SERVICE_SERVICE_PORT': '5000', 'KUBERNETES_PORT_443_TCP_PROTO': 'tcp', 'KUBERNETES_PORT_443_TCP_ADDR': '10.96.0.1', 'CONDA_DEFAULT_ENV': 'base', 'SNOWFLAKE_SERVICE_NAME': 'SERVICE_D997D326EC8511EE95B1369145349CE2', 'KUBERNETES_SERVICE_HOST': '10.96.0.1', 'LC_ALL': 'C.UTF-8', 'KUBERNETES_PORT': 'tcp://10.96.0.1:443', 'KUBERNETES_PORT_443_TCP_PORT': '443', 'SERVICE_PORT': 'tcp://10.103.116.188:5000', 'PATH': '/opt/conda/bin:/opt/conda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'MODEL_ZIP_STAGE_PATH': '/DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2/model.zip', 'SERVER_SOFTWARE': 'gunicorn/21.2.0'})\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:59 +0000] [24] [INFO] Started server process [24]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:59 +0000] [24] [INFO] Waiting for application startup.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:59 +0000] [24] [INFO] Application startup complete.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:59 +0000] [24] [INFO] Extracting model zip from /DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2/model.zip to /tmp/tmpiwbzmba0/extracted_model_dir\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:41:59 +0000] [24] [INFO] Loading model from /tmp/tmpiwbzmba0/extracted_model_dir into memory\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:/opt/conda/lib/python3.10/site-packages/snowflake/ml/model/_packager/model_env/model_env.py:335: UserWarning: Found dependencies specified as pip requirements. This may prevent model deploying to Snowflake Warehouse.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  warnings.warn(\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:There's total 1 GPUs visible to use.\n",
      "Downloading tokenizer_config.json: 100%|██████████| 1.62k/1.62k [00:00<00:00, 9.78MB/s]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 2.57MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 12.7MB/s]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Using pad_token, but it is not set yet.\n",
      "Downloading config.json: 100%|██████████| 614/614 [00:00<00:00, 5.29MB/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 146MB/s]\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 21.0M/9.98G [00:00<00:48, 204MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 52.4M/9.98G [00:00<00:43, 227MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 83.9M/9.98G [00:00<00:41, 237MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 115M/9.98G [00:00<00:40, 243MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|▏         | 147M/9.98G [00:00<00:39, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 178M/9.98G [00:00<00:40, 239MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 210M/9.98G [00:00<00:39, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 241M/9.98G [00:00<00:39, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 273M/9.98G [00:01<00:39, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 304M/9.98G [00:01<00:38, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 336M/9.98G [00:01<00:37, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▎         | 367M/9.98G [00:01<00:37, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 398M/9.98G [00:01<00:37, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 430M/9.98G [00:01<00:37, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 461M/9.98G [00:01<00:37, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 493M/9.98G [00:01<00:37, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▌         | 524M/9.98G [00:02<00:36, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 556M/9.98G [00:02<00:35, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 587M/9.98G [00:02<00:34, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 619M/9.98G [00:02<00:33, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 650M/9.98G [00:02<00:35, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 682M/9.98G [00:02<00:35, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 713M/9.98G [00:02<00:35, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 744M/9.98G [00:02<00:36, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 776M/9.98G [00:03<00:35, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 807M/9.98G [00:03<00:35, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 839M/9.98G [00:03<00:35, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▊         | 870M/9.98G [00:03<00:35, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 902M/9.98G [00:03<00:35, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 933M/9.98G [00:03<00:34, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 965M/9.98G [00:03<00:35, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|▉         | 996M/9.98G [00:03<00:35, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 1.03G/9.98G [00:04<00:35, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.06G/9.98G [00:04<00:34, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.09G/9.98G [00:04<00:33, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 1.12G/9.98G [00:04<00:32, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.15G/9.98G [00:04<00:33, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.18G/9.98G [00:04<00:34, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 1.22G/9.98G [00:04<00:35, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.25G/9.98G [00:04<00:34, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.28G/9.98G [00:05<00:34, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.31G/9.98G [00:05<00:33, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 1.34G/9.98G [00:05<00:32, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.37G/9.98G [00:05<00:32, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.41G/9.98G [00:05<00:33, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 1.44G/9.98G [00:05<00:33, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 1.47G/9.98G [00:05<00:32, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.50G/9.98G [00:05<00:31, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▌        | 1.53G/9.98G [00:06<00:36, 231MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.56G/9.98G [00:06<00:33, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 1.59G/9.98G [00:06<00:34, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▋        | 1.63G/9.98G [00:06<00:34, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.66G/9.98G [00:06<00:33, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.69G/9.98G [00:06<00:34, 239MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 1.72G/9.98G [00:06<00:32, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.75G/9.98G [00:06<00:31, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.78G/9.98G [00:06<00:30, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.81G/9.98G [00:07<00:28, 283MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 1.85G/9.98G [00:07<00:30, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.88G/9.98G [00:07<00:31, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.91G/9.98G [00:07<00:31, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 1.94G/9.98G [00:07<00:30, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  20%|█▉        | 1.97G/9.98G [00:07<00:29, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 2.00G/9.98G [00:07<00:29, 273MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.07G/9.98G [00:08<00:29, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 2.10G/9.98G [00:08<00:29, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██▏       | 2.13G/9.98G [00:08<00:29, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.16G/9.98G [00:08<00:28, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.19G/9.98G [00:08<00:28, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 2.22G/9.98G [00:08<00:27, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.25G/9.98G [00:08<00:26, 289MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.29G/9.98G [00:08<00:28, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 2.32G/9.98G [00:08<00:28, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▎       | 2.35G/9.98G [00:09<00:28, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.38G/9.98G [00:09<00:27, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.41G/9.98G [00:09<00:29, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▍       | 2.44G/9.98G [00:09<00:30, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 2.47G/9.98G [00:09<00:30, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.51G/9.98G [00:09<00:29, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 2.54G/9.98G [00:09<00:28, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.57G/9.98G [00:09<00:27, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▌       | 2.60G/9.98G [00:10<00:26, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 2.63G/9.98G [00:10<00:27, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.66G/9.98G [00:10<00:27, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.69G/9.98G [00:10<00:28, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 2.73G/9.98G [00:10<00:27, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.76G/9.98G [00:10<00:26, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.79G/9.98G [00:10<00:42, 169MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 2.82G/9.98G [00:11<00:38, 186MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▊       | 2.85G/9.98G [00:11<00:35, 201MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.88G/9.98G [00:11<00:32, 217MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 2.92G/9.98G [00:11<00:30, 235MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.95G/9.98G [00:11<00:28, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 2.98G/9.98G [00:11<00:27, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.01G/9.98G [00:11<00:27, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|███       | 3.04G/9.98G [00:11<00:28, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.07G/9.98G [00:12<00:27, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 3.10G/9.98G [00:12<00:27, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███▏      | 3.14G/9.98G [00:12<00:25, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.17G/9.98G [00:12<00:26, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.20G/9.98G [00:12<00:27, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 3.23G/9.98G [00:12<00:27, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.26G/9.98G [00:12<00:27, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.29G/9.98G [00:12<00:26, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 3.32G/9.98G [00:13<00:25, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 3.36G/9.98G [00:13<00:24, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.39G/9.98G [00:13<00:25, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 3.42G/9.98G [00:13<00:26, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.45G/9.98G [00:13<00:26, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 3.48G/9.98G [00:13<00:25, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 3.51G/9.98G [00:13<00:25, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.54G/9.98G [00:13<00:25, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.58G/9.98G [00:14<00:25, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 3.61G/9.98G [00:14<00:24, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▋      | 3.64G/9.98G [00:14<00:24, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.67G/9.98G [00:14<00:23, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.70G/9.98G [00:14<00:23, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 3.73G/9.98G [00:14<00:22, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.76G/9.98G [00:14<00:22, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.80G/9.98G [00:14<00:22, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 3.83G/9.98G [00:14<00:23, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 3.86G/9.98G [00:15<00:23, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.89G/9.98G [00:15<00:23, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▉      | 3.92G/9.98G [00:15<00:22, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.95G/9.98G [00:15<00:22, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 3.98G/9.98G [00:15<00:21, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 4.02G/9.98G [00:15<00:22, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.05G/9.98G [00:15<00:23, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.08G/9.98G [00:15<00:23, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  41%|████      | 4.11G/9.98G [00:16<00:23, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.14G/9.98G [00:16<00:23, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.17G/9.98G [00:16<00:23, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.20G/9.98G [00:16<00:22, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 4.24G/9.98G [00:16<00:21, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.27G/9.98G [00:16<00:21, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.30G/9.98G [00:16<00:20, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 4.33G/9.98G [00:16<00:21, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▎     | 4.36G/9.98G [00:17<00:21, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.39G/9.98G [00:17<00:21, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 4.42G/9.98G [00:17<00:21, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.46G/9.98G [00:17<00:20, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 4.49G/9.98G [00:17<00:19, 276MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▌     | 4.52G/9.98G [00:17<00:19, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.55G/9.98G [00:17<00:19, 283MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.58G/9.98G [00:17<00:20, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 4.61G/9.98G [00:17<00:20, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.65G/9.98G [00:18<00:20, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 4.68G/9.98G [00:18<00:20, 264MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.74G/9.98G [00:18<00:20, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.77G/9.98G [00:18<00:21, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.80G/9.98G [00:18<00:20, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 4.83G/9.98G [00:18<00:20, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.87G/9.98G [00:18<00:19, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.90G/9.98G [00:19<00:18, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 4.93G/9.98G [00:19<00:18, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|████▉     | 4.96G/9.98G [00:19<00:18, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 4.99G/9.98G [00:19<00:17, 283MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 5.02G/9.98G [00:19<00:17, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.05G/9.98G [00:19<00:18, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 5.09G/9.98G [00:19<00:18, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████▏    | 5.12G/9.98G [00:19<00:17, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.15G/9.98G [00:19<00:17, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.18G/9.98G [00:20<00:17, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.21G/9.98G [00:20<00:18, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.24G/9.98G [00:20<00:18, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.27G/9.98G [00:20<00:18, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.31G/9.98G [00:20<00:18, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.34G/9.98G [00:20<00:17, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.37G/9.98G [00:20<00:17, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.40G/9.98G [00:20<00:16, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.43G/9.98G [00:21<00:17, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.46G/9.98G [00:21<00:17, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.49G/9.98G [00:21<00:16, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.53G/9.98G [00:21<00:17, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.56G/9.98G [00:21<00:17, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.59G/9.98G [00:21<00:16, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▋    | 5.62G/9.98G [00:21<00:16, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.65G/9.98G [00:21<00:15, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.68G/9.98G [00:22<00:15, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.71G/9.98G [00:22<00:14, 289MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.75G/9.98G [00:22<00:15, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.78G/9.98G [00:22<00:16, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.81G/9.98G [00:22<00:16, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▊    | 5.84G/9.98G [00:22<00:16, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.87G/9.98G [00:22<00:15, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.90G/9.98G [00:22<00:14, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.93G/9.98G [00:22<00:14, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.97G/9.98G [00:23<00:14, 286MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.00G/9.98G [00:23<00:14, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 6.03G/9.98G [00:23<00:15, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.06G/9.98G [00:23<00:15, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 6.09G/9.98G [00:23<00:14, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.12G/9.98G [00:23<00:14, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.16G/9.98G [00:23<00:13, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.19G/9.98G [00:23<00:14, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.22G/9.98G [00:24<00:14, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.25G/9.98G [00:24<00:14, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.28G/9.98G [00:24<00:14, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.31G/9.98G [00:24<00:13, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.34G/9.98G [00:24<00:13, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.38G/9.98G [00:24<00:13, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.41G/9.98G [00:24<00:13, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.44G/9.98G [00:24<00:13, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.47G/9.98G [00:24<00:13, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.50G/9.98G [00:25<00:12, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.53G/9.98G [00:25<00:12, 276MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.56G/9.98G [00:25<00:12, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.60G/9.98G [00:25<00:11, 288MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▋   | 6.63G/9.98G [00:25<00:12, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.66G/9.98G [00:25<00:12, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.69G/9.98G [00:25<00:12, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.72G/9.98G [00:25<00:12, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.75G/9.98G [00:26<00:11, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.78G/9.98G [00:26<00:11, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.82G/9.98G [00:26<00:11, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.85G/9.98G [00:26<00:11, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.88G/9.98G [00:26<00:11, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.91G/9.98G [00:26<00:11, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.94G/9.98G [00:26<00:11, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.97G/9.98G [00:26<00:12, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 7.00G/9.98G [00:27<00:12, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.04G/9.98G [00:27<00:12, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.07G/9.98G [00:27<00:11, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 7.10G/9.98G [00:27<00:11, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.13G/9.98G [00:27<00:10, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.16G/9.98G [00:27<00:10, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.19G/9.98G [00:27<00:10, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.22G/9.98G [00:27<00:10, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.26G/9.98G [00:27<00:10, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.29G/9.98G [00:28<00:09, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.32G/9.98G [00:28<00:09, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 7.35G/9.98G [00:28<00:09, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.38G/9.98G [00:28<00:10, 258MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.44G/9.98G [00:28<00:10, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.48G/9.98G [00:28<00:09, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.51G/9.98G [00:28<00:09, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.54G/9.98G [00:29<00:09, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.57G/9.98G [00:29<00:09, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.60G/9.98G [00:29<00:09, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.63G/9.98G [00:29<00:09, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.67G/9.98G [00:29<00:08, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.70G/9.98G [00:29<00:09, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.73G/9.98G [00:29<00:08, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.76G/9.98G [00:29<00:08, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.79G/9.98G [00:30<00:08, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.82G/9.98G [00:30<00:08, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.85G/9.98G [00:30<00:07, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.89G/9.98G [00:30<00:07, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.92G/9.98G [00:30<00:07, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.95G/9.98G [00:30<00:07, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.98G/9.98G [00:30<00:07, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|████████  | 8.01G/9.98G [00:30<00:07, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.04G/9.98G [00:31<00:11, 167MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.07G/9.98G [00:31<00:10, 186MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 8.11G/9.98G [00:31<00:09, 202MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.14G/9.98G [00:31<00:08, 217MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.17G/9.98G [00:31<00:10, 175MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.19G/9.98G [00:32<00:11, 149MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.21G/9.98G [00:32<00:12, 137MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.23G/9.98G [00:32<00:14, 121MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.25G/9.98G [00:32<00:17, 97.7MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.27G/9.98G [00:33<00:22, 75.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.28G/9.98G [00:33<00:28, 59.6MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.29G/9.98G [00:34<00:40, 42.0MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.30G/9.98G [00:34<00:54, 30.5MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.32G/9.98G [00:35<01:13, 22.7MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.33G/9.98G [00:36<01:37, 17.0MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▎ | 8.34G/9.98G [00:37<01:55, 14.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.37G/9.98G [00:37<00:56, 28.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.40G/9.98G [00:38<00:34, 46.0MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.43G/9.98G [00:38<00:23, 66.3MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.46G/9.98G [00:38<00:16, 89.1MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.49G/9.98G [00:38<00:13, 114MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.52G/9.98G [00:38<00:10, 138MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.56G/9.98G [00:38<00:08, 165MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▋ | 8.62G/9.98G [00:38<00:06, 215MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.65G/9.98G [00:39<00:05, 224MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.68G/9.98G [00:39<00:05, 230MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.71G/9.98G [00:39<00:05, 234MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.75G/9.98G [00:39<00:05, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.78G/9.98G [00:39<00:04, 245MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.81G/9.98G [00:39<00:04, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.84G/9.98G [00:39<00:04, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.87G/9.98G [00:39<00:04, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.90G/9.98G [00:40<00:04, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.93G/9.98G [00:40<00:03, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.97G/9.98G [00:40<00:03, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.00G/9.98G [00:40<00:03, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|█████████ | 9.03G/9.98G [00:40<00:03, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.06G/9.98G [00:40<00:03, 241MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 9.09G/9.98G [00:40<00:03, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████▏| 9.12G/9.98G [00:40<00:03, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.15G/9.98G [00:41<00:03, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.19G/9.98G [00:41<00:03, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.22G/9.98G [00:41<00:03, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.25G/9.98G [00:41<00:02, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.28G/9.98G [00:41<00:02, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.31G/9.98G [00:41<00:02, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▎| 9.34G/9.98G [00:41<00:02, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.37G/9.98G [00:41<00:02, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.41G/9.98G [00:42<00:02, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.44G/9.98G [00:42<00:02, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.47G/9.98G [00:42<00:01, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.50G/9.98G [00:42<00:02, 176MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.53G/9.98G [00:42<00:02, 199MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.56G/9.98G [00:42<00:01, 217MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.59G/9.98G [00:42<00:01, 225MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.63G/9.98G [00:43<00:01, 232MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.66G/9.98G [00:43<00:01, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.69G/9.98G [00:43<00:01, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.72G/9.98G [00:43<00:00, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.75G/9.98G [00:43<00:00, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.78G/9.98G [00:43<00:00, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.81G/9.98G [00:43<00:00, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.85G/9.98G [00:43<00:00, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.88G/9.98G [00:44<00:00, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.91G/9.98G [00:44<00:00, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.94G/9.98G [00:44<00:00, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [00:44<00:00, 225MB/s]\u001b[A\n",
      "Downloading shards:  50%|█████     | 1/2 [00:44<00:44, 44.52s/it]\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   0%|          | 10.5M/3.50G [00:00<00:58, 60.1MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   1%|          | 41.9M/3.50G [00:00<00:23, 145MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:   2%|▏         | 73.4M/3.50G [00:00<00:18, 187MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   3%|▎         | 105M/3.50G [00:00<00:15, 213MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:   4%|▍         | 136M/3.50G [00:00<00:14, 231MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   5%|▍         | 168M/3.50G [00:00<00:13, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   6%|▌         | 199M/3.50G [00:00<00:12, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 231M/3.50G [00:01<00:12, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   7%|▋         | 262M/3.50G [00:01<00:12, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   8%|▊         | 294M/3.50G [00:01<00:12, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:   9%|▉         | 325M/3.50G [00:01<00:11, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  10%|█         | 357M/3.50G [00:01<00:11, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  11%|█         | 388M/3.50G [00:01<00:11, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  12%|█▏        | 419M/3.50G [00:01<00:12, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  13%|█▎        | 451M/3.50G [00:01<00:11, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  14%|█▍        | 482M/3.50G [00:01<00:11, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  15%|█▍        | 514M/3.50G [00:02<00:11, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▌        | 545M/3.50G [00:02<00:10, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  16%|█▋        | 577M/3.50G [00:02<00:11, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  17%|█▋        | 608M/3.50G [00:02<00:11, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  18%|█▊        | 640M/3.50G [00:02<00:11, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  19%|█▉        | 671M/3.50G [00:02<00:11, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  20%|██        | 703M/3.50G [00:02<00:10, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  21%|██        | 734M/3.50G [00:02<00:10, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  22%|██▏       | 765M/3.50G [00:03<00:10, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  23%|██▎       | 797M/3.50G [00:03<00:11, 235MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  24%|██▎       | 828M/3.50G [00:03<00:11, 226MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▍       | 860M/3.50G [00:03<00:12, 217MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  25%|██▌       | 891M/3.50G [00:03<00:12, 208MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  26%|██▋       | 923M/3.50G [00:03<00:12, 207MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  27%|██▋       | 944M/3.50G [00:04<00:14, 177MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 965M/3.50G [00:04<00:17, 148MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  28%|██▊       | 986M/3.50G [00:04<00:19, 130MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  29%|██▉       | 1.03G/3.50G [00:04<00:21, 114MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  30%|██▉       | 1.05G/3.50G [00:05<00:22, 109MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 1.07G/3.50G [00:05<00:23, 104MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  31%|███       | 1.09G/3.50G [00:05<00:23, 105MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 1.11G/3.50G [00:05<00:23, 102MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 1.12G/3.50G [00:05<00:28, 83.7MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  32%|███▏      | 1.13G/3.50G [00:06<00:32, 73.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 1.14G/3.50G [00:06<00:35, 66.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 1.15G/3.50G [00:06<00:37, 61.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  33%|███▎      | 1.16G/3.50G [00:06<00:40, 58.3MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▎      | 1.17G/3.50G [00:07<00:41, 55.5MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 1.18G/3.50G [00:07<00:43, 53.5MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 1.20G/3.50G [00:07<00:44, 51.3MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  34%|███▍      | 1.21G/3.50G [00:07<00:54, 42.4MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▍      | 1.22G/3.50G [00:08<01:03, 36.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 1.23G/3.50G [00:08<01:24, 27.0MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  35%|███▌      | 1.24G/3.50G [00:09<01:25, 26.5MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 1.25G/3.50G [00:10<01:53, 19.9MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  36%|███▌      | 1.26G/3.50G [00:11<02:55, 12.7MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 1.28G/3.50G [00:19<09:15, 4.00MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  37%|███▋      | 1.29G/3.50G [00:24<11:24, 3.23MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  38%|███▊      | 1.32G/3.50G [00:24<05:00, 7.24MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  39%|███▊      | 1.35G/3.50G [00:24<02:48, 12.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|███▉      | 1.38G/3.50G [00:24<01:44, 20.2MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  40%|████      | 1.42G/3.50G [00:25<01:08, 30.2MB/s]\u001b[A\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "Downloading (…)of-00002.safetensors:  42%|████▏     | 1.48G/3.50G [00:25<00:34, 58.8MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  43%|████▎     | 1.51G/3.50G [00:25<00:25, 77.6MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  44%|████▍     | 1.54G/3.50G [00:25<00:19, 99.1MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  45%|████▍     | 1.57G/3.50G [00:25<00:15, 123MB/s] \u001b[A\n",
      "Downloading (…)of-00002.safetensors:  46%|████▌     | 1.60G/3.50G [00:25<00:12, 149MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  47%|████▋     | 1.64G/3.50G [00:25<00:10, 172MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  48%|████▊     | 1.67G/3.50G [00:26<00:09, 194MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▊     | 1.70G/3.50G [00:26<00:08, 216MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  49%|████▉     | 1.73G/3.50G [00:26<00:07, 231MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  50%|█████     | 1.76G/3.50G [00:26<00:07, 235MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  51%|█████     | 1.79G/3.50G [00:26<00:07, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.82G/3.50G [00:26<00:06, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.86G/3.50G [00:26<00:06, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  54%|█████▍    | 1.89G/3.50G [00:26<00:05, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  55%|█████▍    | 1.92G/3.50G [00:26<00:06, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  56%|█████▌    | 1.95G/3.50G [00:27<00:06, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  57%|█████▋    | 1.98G/3.50G [00:27<00:05, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.01G/3.50G [00:27<00:05, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.04G/3.50G [00:27<00:05, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  59%|█████▉    | 2.08G/3.50G [00:27<00:05, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  60%|██████    | 2.11G/3.50G [00:27<00:05, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  61%|██████    | 2.14G/3.50G [00:27<00:05, 269MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.17G/3.50G [00:27<00:05, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  63%|██████▎   | 2.20G/3.50G [00:28<00:04, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.23G/3.50G [00:28<00:04, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  65%|██████▍   | 2.26G/3.50G [00:28<00:04, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.30G/3.50G [00:28<00:04, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.33G/3.50G [00:28<00:04, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.36G/3.50G [00:28<00:04, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  68%|██████▊   | 2.39G/3.50G [00:28<00:04, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  69%|██████▉   | 2.42G/3.50G [00:28<00:04, 268MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  70%|███████   | 2.45G/3.50G [00:29<00:04, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  71%|███████   | 2.49G/3.50G [00:29<00:04, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.52G/3.50G [00:29<00:03, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  73%|███████▎  | 2.55G/3.50G [00:29<00:03, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  74%|███████▎  | 2.58G/3.50G [00:29<00:03, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▍  | 2.61G/3.50G [00:29<00:03, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  75%|███████▌  | 2.64G/3.50G [00:29<00:03, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  76%|███████▋  | 2.67G/3.50G [00:29<00:03, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  77%|███████▋  | 2.71G/3.50G [00:30<00:03, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.74G/3.50G [00:30<00:03, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  79%|███████▉  | 2.77G/3.50G [00:30<00:03, 218MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  80%|███████▉  | 2.80G/3.50G [00:30<00:03, 225MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  81%|████████  | 2.83G/3.50G [00:30<00:02, 234MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  82%|████████▏ | 2.86G/3.50G [00:30<00:02, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  83%|████████▎ | 2.89G/3.50G [00:30<00:02, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▎ | 2.93G/3.50G [00:30<00:02, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  84%|████████▍ | 2.96G/3.50G [00:31<00:02, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  85%|████████▌ | 2.99G/3.50G [00:31<00:02, 207MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  86%|████████▋ | 3.02G/3.50G [00:31<00:03, 137MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.05G/3.50G [00:31<00:02, 162MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  88%|████████▊ | 3.08G/3.50G [00:31<00:02, 188MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  89%|████████▉ | 3.11G/3.50G [00:32<00:01, 201MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  90%|████████▉ | 3.15G/3.50G [00:32<00:01, 213MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  91%|█████████ | 3.18G/3.50G [00:32<00:01, 225MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  92%|█████████▏| 3.21G/3.50G [00:32<00:01, 238MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.24G/3.50G [00:32<00:01, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.27G/3.50G [00:32<00:00, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  94%|█████████▍| 3.30G/3.50G [00:32<00:00, 257MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  95%|█████████▌| 3.33G/3.50G [00:32<00:00, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  96%|█████████▌| 3.37G/3.50G [00:33<00:00, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  97%|█████████▋| 3.40G/3.50G [00:33<00:00, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  98%|█████████▊| 3.43G/3.50G [00:33<00:00, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.46G/3.50G [00:33<00:00, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:33<00:00, 104MB/s]\u001b[A\n",
      "Downloading shards: 100%|██████████| 2/2 [01:18<00:00, 39.09s/it]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:  warnings.warn(\n",
      "Downloading generation_config.json: 100%|██████████| 188/188 [00:00<00:00, 1.14MB/s]\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:After GC on model.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Torch VRAM 0.0 MB allocated.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Torch VRAM 0.0 MB reserved.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:INFO 03-27 22:45:18 llm_engine.py:72] Initializing an LLM engine with config: model='/tmp/tmp40iwwow1', tokenizer='/tmp/tmp40iwwow1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:[2024-03-27 22:45:59 +0000] [24] [INFO] Successfully loaded model into memory\n",
      "INFO:snowflake.ml._internal.utils.log_stream_processor:\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Service DASH_DB.DASH_SCHEMA.service_d997d326ec8511ee95b1369145349ce2 is ready. Creating service function...\n",
      "INFO:snowflake.ml._internal.utils.spcs_attribution_utils:Service DASH_DB.DASH_SCHEMA.service_d997d326ec8511ee95b1369145349ce2 created with compute pool DASH_GPU3.\n",
      "INFO:snowflake.ml.model._deploy_client.snowservice.deploy:Service function DASH_DB.DASH_SCHEMA.llama_predict is created. Deployment completed successfully!\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS ( CREATION_TIME,DEP...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA ( ATTRIBUTE_NAME,EVENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 356 ms, total: 2.26 s\n",
      "Wall time: 26min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.ml.registry.model_registry.ModelReference at 0x7fa3f1488b80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llama_model_ref.deploy(\n",
    "    deployment_name=\"llama_predict\", \n",
    "    platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    permanent=True, \n",
    "    options={\"compute_pool\": SNOWFLAKE_COMPUTE_POOL, \"num_gpus\": 1, \"external_access_integrations\": [\"ALLOW_ALL_ACCESS_INTEGRATION\"]})\n",
    "\n",
    "llama_model_ref = model_registry.ModelReference(registry=registry,model_name=MODEL_NAME,model_version=MODEL_VERSION)\n",
    "llama_model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from JSON into Snowflake\n",
    "\n",
    "*NOTE: Reading data in JSON and storing it in a Snowflake table are one time operations. Once the data is loaded, use Snowpark to load the data from the existing table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [CREATE TEMP STAGE /* Python:snowflake.connector.pandas_tools.write_pandas() */ y...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [PUT /* Python:snowflake.connector.pandas_tools.write_pandas() */ 'file:///tmp/tm...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [CREATE TEMP FILE FORMAT wlpcvmsmre /* Python:snowflake.connector.pandas_tools.wr...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT COLUMN_NAME, TYPE FROM table(infer_schema(location=>'@yydjmskpwy', file_f...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 6\n",
      "INFO:snowflake.connector.cursor:query: [CREATE  TABLE IF NOT EXISTS vaoolgqsil (LANGUAGE TEXT, TRANSCRIPT TEXT, NAME TEX...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [COPY INTO vaoolgqsil /* Python:snowflake.connector.pandas_tools.write_pandas() *...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [DROP TABLE IF EXISTS transcripts /* Python:snowflake.connector.pandas_tools.writ...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [ALTER TABLE vaoolgqsil RENAME TO transcripts /* Python:snowflake.connector.panda...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (transcripts)]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>TRANSCRIPT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>TOY_LIST</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>[\\n  \"Barbie Science Lab Playset\"\\n]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>[\\n  \"Barbie Dreamhouse 2023\"\\n]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Auckland</td>\n",
       "      <td>[\\n  \"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"\\n]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!</td>\n",
       "      <td>Karen</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>[\\n  \"Orijin Bees Lovey Coiley Baby Bee\"\\n]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>[\\n  \"Gabbys Dollhouse Cruise Ship\"\\n]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LANGUAGE  \\\n",
       "0       EN   \n",
       "1       EN   \n",
       "2       EN   \n",
       "3       EN   \n",
       "4       EN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           TRANSCRIPT  \\\n",
       "0  caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!   \n",
       "1                                                                                                                                                 caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!   \n",
       "2                                                                                                                                                                                                                                                                                                                               caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!   \n",
       "3                                                                                                                                                                                                                                                                                                                                      caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!   \n",
       "\n",
       "      NAME     LOCATION  \\\n",
       "0   Rachel       Sydney   \n",
       "1  Jessica  Los Angeles   \n",
       "2   Ashley     Auckland   \n",
       "3    Karen    Vancouver   \n",
       "4    Sarah     Brisbane   \n",
       "\n",
       "                                                                        TOY_LIST  \\\n",
       "0                                           [\\n  \"Barbie Science Lab Playset\"\\n]   \n",
       "1                                               [\\n  \"Barbie Dreamhouse 2023\"\\n]   \n",
       "2  [\\n  \"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"\\n]   \n",
       "3                                    [\\n  \"Orijin Bees Lovey Coiley Baby Bee\"\\n]   \n",
       "4                                         [\\n  \"Gabbys Dollhouse Cruise Ship\"\\n]   \n",
       "\n",
       "   ID  \n",
       "0   0  \n",
       "1   2  \n",
       "2   4  \n",
       "3   5  \n",
       "4   6  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"transcripts_base.json\",lines=True)\n",
    "sf_df = session.write_pandas(df,'transcripts',auto_create_table=True,quote_identifiers=False,overwrite=True)\n",
    "sf_df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompt Engineering Example\n",
    "\n",
    "For every transcript, define summarization instruction for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM transcripts]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT concat_ws(' ', '\\n[INST] Summarize this transcript in less than 200 words...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       input\n",
       "0  \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]\n",
       "1                                                                                                                                                 \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]\n",
       "2                                                                                                                                                                                                                                                                                                                               \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]\n",
       "3                                                                                                                                                                                                                                                                                                                                      \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] Summarize this transcript in less than 200 words: \n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "df_inputs = sf_df.with_column('\"input\"',F.concat_ws(F.lit(\" \"),F.lit(begin_prompt),F.col('transcript'),F.lit(end_prompt))).select('\"input\"')\n",
    "df_inputs.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using Simple Prompt\n",
    "\n",
    "Pass the summariation instruction to the LLM and examine results of 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT \"MODEL_NAME\", \"MODEL_VERSION...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"MODEL_NAME\", \"MODEL_VERSION\", \"DEPLOYMENT_NAME\", \"CREATION_TIME\", \"TARGE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"input\",  CAST (\"TMP_RESULT\"['generated_text'] AS STRING) AS \"generated_t...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Rachel from Sydney calls to submit her holiday wish list to Frosty. She is considering the Barbie Science Lab Playset for her daughter, who enjoys science and Barbie. Frosty suggests an alternative, the Beast Lab: Shark Beast Creator, which is a creative and educational toy. Rachel decides to stick with the original choice and thanks Frosty for his help.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Jessica, a caller from Los Angeles, is looking for a toy for her child that promotes imaginative play and creativity. Frosty suggests the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Jessica decides on the Barbie Dreamhouse, and Frosty asks about her favorite holiday memories. Jessica shares a memory of seeing the city's holiday lights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>Ashley from Auckland called Frosty to find a gift for her nephew, who loves vehicles and action figures. Frosty suggested the Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van, which Ashley added to her wish list. Ashley also shared her own hobby of hiking and exploring nature, which Frosty appreciated. The call ended with Frosty wishing Ashley a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]</td>\n",
       "      <td>Karen from Vancouver called Frosty to find a gift for her 4-year-old niece, who loves dolls and plush toys. Frosty recommended the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset. Karen chose the baby bee doll, and Frosty shared a holiday memory of visiting a winter festival with ice sculptures and live performances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]</td>\n",
       "      <td>A caller named Sarah from Brisbane is looking for a gift for her daughter who loves playing with dolls and animals. Frosty suggests the Gabbys Dollhouse Cruise Ship, which combines both. Sarah adds it to her wish list and Frosty wishes her a happy holiday season.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       input  \\\n",
       "0  \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "1                                                                                                                                                 \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "2                                                                                                                                                                                                                                                                                                                               \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!  [/INST]   \n",
       "3                                                                                                                                                                                                                                                                                                                                      \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!  [/INST]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    \\n[INST] Summarize this transcript in less than 200 words: \\n caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!  [/INST]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                     generated_text  \n",
       "0              Rachel from Sydney calls to submit her holiday wish list to Frosty. She is considering the Barbie Science Lab Playset for her daughter, who enjoys science and Barbie. Frosty suggests an alternative, the Beast Lab: Shark Beast Creator, which is a creative and educational toy. Rachel decides to stick with the original choice and thanks Frosty for his help.  \n",
       "1     Jessica, a caller from Los Angeles, is looking for a toy for her child that promotes imaginative play and creativity. Frosty suggests the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Jessica decides on the Barbie Dreamhouse, and Frosty asks about her favorite holiday memories. Jessica shares a memory of seeing the city's holiday lights  \n",
       "2    Ashley from Auckland called Frosty to find a gift for her nephew, who loves vehicles and action figures. Frosty suggested the Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van, which Ashley added to her wish list. Ashley also shared her own hobby of hiking and exploring nature, which Frosty appreciated. The call ended with Frosty wishing Ashley a  \n",
       "3      Karen from Vancouver called Frosty to find a gift for her 4-year-old niece, who loves dolls and plush toys. Frosty recommended the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset. Karen chose the baby bee doll, and Frosty shared a holiday memory of visiting a winter festival with ice sculptures and live performances  \n",
       "4                                                                                                           A caller named Sarah from Brisbane is looking for a gift for her daughter who loves playing with dolls and animals. Frosty suggests the Gabbys Dollhouse Cruise Ship, which combines both. Sarah adds it to her wish list and Frosty wishes her a happy holiday season.  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict_results = llama_model_ref.predict(deployment_name=\"llama_predict\",data=df_inputs)\n",
    "df_predict_results.select('\"input\"','\"generated_text\"').limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Resources\n",
    "\n",
    "Delete base model service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [show services in compute pool DASH_GPU3]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"name\"                                    |\"database_name\"  |\"schema_name\"  |\"owner\"    |\"compute_pool\"  |\"dns_name\"                                          |\"min_instances\"  |\"max_instances\"  |\"auto_resume\"  |\"external_access_integrations\"    |\"created_on\"                      |\"updated_on\"                      |\"resumed_on\"  |\"comment\"  |\"owner_role_type\"  |\"query_warehouse\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|LLM_SERVICE                               |DASH_DB          |DASH_SCHEMA    |DASH_SPCS  |DASH_GPU3       |llm-service.dash-schema.dash-db.snowflakecomput...  |1                |1                |true           |[\"ALLOW_ALL_ACCESS_INTEGRATION\"]  |2024-03-06 14:52:51.285000-08:00  |2024-03-06 14:52:52.984000-08:00  |NULL          |NULL       |ROLE               |NULL               |\n",
      "|SERVICE_D997D326EC8511EE95B1369145349CE2  |DASH_DB          |DASH_SCHEMA    |DASH_SPCS  |DASH_GPU3       |service-d997d326ec8511ee95b1369145349ce2.dash-s...  |1                |1                |true           |[\"ALLOW_ALL_ACCESS_INTEGRATION\"]  |2024-03-27 15:35:48.131000-07:00  |2024-03-27 15:35:49.297000-07:00  |NULL          |NULL       |ROLE               |NULL               |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(f\"show services in compute pool {SNOWFLAKE_COMPUTE_POOL}\").show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [drop service SERVICE_D997D326EC8511EE95B1369145349CE2]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    }
   ],
   "source": [
    "# Replace SERVICE_XXXXXXXXXXXXXXXXXXXXXX with the one from running the above cell\n",
    "service_id = 'SERVICE_D997D326EC8511EE95B1369145349CE2'\n",
    "session.sql(f\"drop service {service_id}\").collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [show services in compute pool DASH_GPU3]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"name\"       |\"database_name\"  |\"schema_name\"  |\"owner\"    |\"compute_pool\"  |\"dns_name\"                                          |\"min_instances\"  |\"max_instances\"  |\"auto_resume\"  |\"external_access_integrations\"    |\"created_on\"                      |\"updated_on\"                      |\"resumed_on\"  |\"comment\"  |\"owner_role_type\"  |\"query_warehouse\"  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|LLM_SERVICE  |DASH_DB          |DASH_SCHEMA    |DASH_SPCS  |DASH_GPU3       |llm-service.dash-schema.dash-db.snowflakecomput...  |1                |1                |true           |[\"ALLOW_ALL_ACCESS_INTEGRATION\"]  |2024-03-06 14:52:51.285000-08:00  |2024-03-06 14:52:52.984000-08:00  |NULL          |NULL       |ROLE               |NULL               |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.sql(f\"show services in compute pool {SNOWFLAKE_COMPUTE_POOL}\").show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Llama 2 Model\n",
    "\n",
    "Fine-tuning is one form of model training. We start training from a pre-trained model and adjust a set of model parameters to better solve for a concrete task based on task specific data. Today we are going to fine-tune 7B Llama 2 model using LoRA (Low-Rank Adaptation)--which is a parameter efficient way of fine-tuning LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import sys\n",
    "from utils import Concatenator\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import sentencepiece\n",
    "import os\n",
    "import json\n",
    "from transformers import TrainerCallback\n",
    "from contextlib import nullcontext\n",
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "from snowflake.ml.model.models import llm\n",
    "\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "logger = logging.getLogger(\"snowflake.ml\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hugging Face Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token $HUGGING_FACE_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained Llama 2 Model From Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer\n",
      "loading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e930dfcb6e1f4ecfa00b91fadbad6585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b11f96d9e240f18fcfd6291f1f32ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6377304b6fd0405b8fe367e8b4e831a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd778536509f4329b71717c847d0a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11adf0f7fca1406683186ab038c9e020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "print('loading tokenizer')\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "print('loading model')\n",
    "model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def prepare_stratified_dataset(path, seed = 42):\n",
    "#     raw_df = pd.read_json(path, lines=True)\n",
    "#     raw_df['id'] = raw_df.index\n",
    "#     ds = Dataset.from_pandas(raw_df, split='train')\n",
    "#     cl = ClassLabel(num_classes=4, names=[\"EN\", \"FR\", \"DE\", \"ES\"])\n",
    "#     new_features = ds.features.copy()\n",
    "#     new_features['lang_label'] = cl\n",
    "#     cl_d = {l : cl.str2int(l) for l in [\"EN\", \"FR\", \"DE\", \"ES\"]}\n",
    "#     def convert_lang(sample):\n",
    "#         sample['lang_label'] = cl_d[sample['language']]\n",
    "#         return sample\n",
    "#     ds = ds.map(convert_lang, features=new_features)\n",
    "#     ds_split = ds.train_test_split(test_size=0.15, stratify_by_column='lang_label', seed=42)\n",
    "#     test_ds_split = ds_split['test'].train_test_split(test_size=2/3, stratify_by_column='lang_label', seed=42)\n",
    "#     return ds_split['train'].to_pandas(), test_ds_split['train'].to_pandas(), test_ds_split['test'].to_pandas()\n",
    "\n",
    "# train_df, eval_df, test_df = prepare_stratified_dataset(\n",
    "#     'transcripts.json'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 1368\n",
      "Train        : 100\n",
      "Eval         : 100\n",
      "Test         : 100\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"transcripts_inst.json\", lines=True)\n",
    "print(f\"Total records: {df.shape[0]}\")\n",
    "train_df = df.head(100)\n",
    "print(f\"Train        : {train_df.shape[0]}\")\n",
    "eval_df = df[200:300]\n",
    "print(f\"Eval         : {eval_df.shape[0]}\")\n",
    "test_df = df.tail(100)\n",
    "print(f\"Test         : {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Barbie Science Lab Playset\"], \"location\": \"Sydney\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Barbie Dreamhouse 2023\"], \"location\": \"Los Angeles\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"], \"location\": \"Auckland\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Orijin Bees Lovey Coiley Baby Bee\"], \"location\": \"Vancouver\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\"caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!\"</td>\n",
       "      <td>{\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Brisbane\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          instruction  \\\n",
       "0  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "1  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "2  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "3  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "4  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  input  \\\n",
       "0  \"caller: Hi there, Frosty! I am excited to submit my holiday wish list.\\nfrosty: Hello! I'm happy to help you. Can I have your name, please?\\ncaller: I am Rachel, and I am calling from Sydney.\\nfrosty: Great, Rachel! Now, what's on your wish list?\\ncaller: We are thinking of getting the barbie science doll set. But, I'm not quite sure yet.\\nfrosty: That's a wonderful choice! May I ask why you're interested in this toy?\\ncaller: My daughter loves science and Barbie, so it will be a perfect combo for her.\\nfrosty: That sounds perfect indeed. How do you and your family plan to celebrate the holiday season?\\ncaller: We are planning a small gathering with close family and friends and lots of food and games.\\nfrosty: That sounds like a lovely time. Before we confirm your wish list, would you like to explore some other options for your daughter?\\ncaller: Maybe one more option?\\nfrosty: How about the Beast Lab: Shark Beast Creator? It's a fantastic creative and educational toy that your daughter might enjoy, especially if she loves science.\\ncaller: Oh, that sounds interesting. But I think we'll stick with the barbie science doll set.\\nfrosty: Alright, so the Barbie Science Lab Playset will be on the wish list. Thank you for sharing your holiday plans, and I hope your family has a fantastic time. Have a great day, Rachel!\\ncaller: Thank you, Frosty! Happy holidays!\"   \n",
       "1                                                                                                                                                 \"caller: Hi Frosty! My name is Jessica, and I live in Los Angeles. I need some help finding the perfect toy for my little one.\\nfrosty: Hello, Jessica! It's great to have you here. Let's find that perfect toy! What are some of your child's interests or hobbies?\\ncaller: She loves playing dress-up and pretend play. She's also quite artistic.\\nfrosty: That's delightful! I have a couple of suggestions: the Barbie Dreamhouse 2023 or the Calico Critters Pony's Stylish Hair Salon. Both encourage imaginative play and creativity.\\ncaller: Hmm, I like both options. Maybe the new Barbie Dreamhouse?\\nfrosty: The Barbie Dreamhouse 2023 is an excellent choice for hours of endless imaginative play. Before we confirm, is there any other toy you'd like to consider?\\ncaller: No, I think we are good with the Barbie Dreamhouse.\\nfrosty: Fantastic! The Barbie Dreamhouse 2023 is now on your holiday wish list. What's your favorite holiday memory, Jessica?\\ncaller: My favorite memory is when we all went to see the city's holiday lights display. It was magical!\\nfrosty: That sounds enchanting! I hope you and your family create more beautiful memories this holiday season. Have a great day, Jessica!\\ncaller: Thank you, Frosty! Happy holidays!\"   \n",
       "2                                                                                                                                                                                                                                                                                                                               \"caller: Hi, Frosty! My name is Ashley, and I'm calling from Auckland. I need to pick a gift for my nephew, but I'm a little unsure.\\nfrosty: Hello, Ashley! I'm here to help you find the perfect gift. What are your nephew's interests or hobbies?\\ncaller: He is really into vehicles and action figures.\\nfrosty: Great! I have a couple of options for you: The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van or the Bluey Convertible and Figures. Which one sounds more appealing to you?\\ncaller: The ninja turtles delivery van seems perfect! Let's add that to the list.\\nfrosty: Excellent choice! The Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van is now on your wish list. Can you tell me about one of your favorite pastimes or hobbies, Ashley?\\ncaller: Sure! I love spending time in nature, going for hikes and exploring new trails.\\nfrosty: That sounds like an excellent way to unwind and enjoy the world around you. I hope you have a fantastic holiday season, Ashley! Goodbye!\\ncaller: Thank you, Frosty! Happy holidays!\"   \n",
       "3                                                                                                                                                                                                                                                                                                                                      \"caller: Hey Frosty! I need some help finding a gift for my niece. My name is Karen, and I'm from Vancouver.\\nfrosty: Hello, Karen! I'd be happy to help you find the perfect gift. What are some of your niece's interests?\\ncaller: She loves dolls and plush toys. She's always playing pretend with them.\\nfrosty: That's lovely! How about the Orijin Bees Lovey Coiley Baby Bee or the Fisher-Price Little People Mickey and Friends Playset? Both are adorable and encourage imaginative play.\\ncaller: The baby bee doll sounds great. Let's go with that one.\\nfrosty: Wonderful choice! The Orijin Bees Lovey Coiley Baby Bee is now on your holiday wish list. Do you have any favorite holiday memories, Karen?\\ncaller: One of my favorites is when we visited a local winter festival with ice sculptures and live performances. It was truly magical!\\nfrosty: That sounds fantastic! I hope you and your family create more wonderful memories this holiday season. Enjoy your celebrations, and have a great day, Karen!\\ncaller: Thanks, Frosty! You too, and happy holidays!\"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                    \"caller: Hi Frosty, I'm Sarah, calling from Brisbane. I'm looking for a gift for my daughter, but I'm not sure which one to choose.\\nfrosty: Hello, Sarah! I'd be glad to help. Can you tell me more about your daughter's interests or hobbies?\\ncaller: She loves playing with dolls and anything that has to do with animals.\\nfrosty: How lovely! I have a suggestion for you. The Gabbys Dollhouse Cruise Ship is a fantastic toy that combines both dolls and animals. Your daughter might enjoy it.\\ncaller: That sounds fantastic! Let's put that down on our wish list.\\nfrosty: Great! The Gabbys Dollhouse Cruise Ship is now on your wish list. What's something you enjoy the most about this time of the year, Sarah?\\ncaller: I love the festive atmosphere and spending quality time with family and friends.\\nfrosty: That's wonderful, Sarah! I hope you and your family have a fantastic holiday season. Have a great day!\\ncaller: Thank you so much, Frosty! Happy holidays!\"   \n",
       "\n",
       "                                                                                                          output  \\\n",
       "0                                             {\"toy_list\": [\"Barbie Science Lab Playset\"], \"location\": \"Sydney\"}   \n",
       "1                                            {\"toy_list\": [\"Barbie Dreamhouse 2023\"], \"location\": \"Los Angeles\"}   \n",
       "2  {\"toy_list\": [\"Teenage Mutant Ninja Turtles: Mutant Mayhem Pizza Fire Delivery Van\"], \"location\": \"Auckland\"}   \n",
       "3                                   {\"toy_list\": [\"Orijin Bees Lovey Coiley Baby Bee\"], \"location\": \"Vancouver\"}   \n",
       "4                                         {\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Brisbane\"}   \n",
       "\n",
       "  language  \n",
       "0       EN  \n",
       "1       EN  \n",
       "2       EN  \n",
       "3       EN  \n",
       "4       EN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': Dataset.from_pandas(train_df),\n",
    "    'eval': Dataset.from_pandas(eval_df),\n",
    "    'test': Dataset.from_pandas(test_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Prompt to Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "<</SYS>>\n",
    "### Instruction:\n",
    "{{instruction}}\n",
    "### Input:\n",
    "{{input_}}\n",
    "### Output:\n",
    "{{output}}\n",
    "{{eos_token}}\n",
    "\"\"\"\n",
    "\n",
    "eval_prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "<</SYS>>\n",
    "### Instruction:\n",
    "{{instruction}}\n",
    "### Input:\n",
    "{{input_}}\n",
    "### Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe5755bd827433a961966abb8176087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1cded685a94dfdbdf377784888b679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f6553442ac4e94b96afe68f8aee725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_train_template(sample):\n",
    "    return {\n",
    "        \"text\": train_prompt.format(\n",
    "            instruction=sample[\"instruction\"],\n",
    "            input_=sample[\"input\"].replace('\\\\n', '\\n'),\n",
    "            output=sample[\"output\"],\n",
    "            eos_token=tokenizer.eos_token,\n",
    "        )\n",
    "    }\n",
    "\n",
    "def apply_eval_template(sample):\n",
    "    return {\n",
    "        \"text\": eval_prompt.format(\n",
    "            instruction=sample[\"instruction\"],\n",
    "            input_=sample[\"input\"].replace('\\\\n', '\\n')\n",
    "        )\n",
    "    }\n",
    "\n",
    "#applying template\n",
    "\n",
    "datasets['train'] = datasets['train'].map(apply_train_template, remove_columns=list(datasets['train'].features))\n",
    "for k in ['eval', 'test']:\n",
    "    datasets[k] = datasets[k].map(apply_eval_template, remove_columns=list(datasets[k].features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d65aeaa444a46019bf4376b81e40270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dbbf7edbaf4169b741a871fed6a30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb216084633d4fad8561f987c89e653e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84c51a3327c4f1b979d61d8b112c4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a10ce0a0564074ac6e7193e4ac5a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dab820b1b804a87a1742575f518d5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in datasets.items():\n",
    "    datasets[k] = v.map(\n",
    "        lambda sample: tokenizer(sample[\"text\"]),\n",
    "        batched=True,\n",
    "        \n",
    "        remove_columns=list(v.features),\n",
    "    ).map(Concatenator(), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Configuration\n",
    "\n",
    "Instead of adjusting all the ~7B parameters, LoRA allows us to adjust only a percent of model weights--which can save compute and memory resources dramatically. For this lab, we will fine-tune our model using LoRA on a single A10 GPU. This will demostrate how good the inference can be on fine-tuned models even with limited compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "#setting the model into training mode\n",
    "model.train()\n",
    "\n",
    "#setting up training\n",
    "def create_peft_config(model):\n",
    "    from peft import (\n",
    "        get_peft_model,\n",
    "        LoraConfig,\n",
    "        TaskType,\n",
    "        prepare_model_for_kbit_training,\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules = [\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "\n",
    "    # prepare int-8 model for training\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model, peft_config\n",
    "\n",
    "# create peft config\n",
    "model, lora_config = create_peft_config(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -r output_weights_dir # deletes prior fine tuning weights\n",
    "!mkdir output_weights_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're passing train_dataset and eval_dataset that are used to generate loss calculation during fine-tuning process and we've set output_weights_dir as the directory where the fine-tuned weights will be stored after fine-tuning job completes.\n",
    "\n",
    "To achieve good performance for the task, you will need at least 1 num_epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"output_weights_dir\"\n",
    "enable_profiler = False\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 1,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'per_device_train_batch_size': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,  # Use BF16 if available\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=total_steps if enable_profiler else -1,\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.181, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 01:23, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profiler = nullcontext() \n",
    "\n",
    "with profiler:\n",
    "    # Create Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets['train'],\n",
    "        eval_dataset=datasets['eval'],\n",
    "        data_collator=default_data_collator,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "    \n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log and Deploy Fine-tuned Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97/41704961.py:5: DeprecationWarning: \n",
      "The `snowflake.ml.registry.model_registry.ModelRegistry` has been deprecated starting from version 1.2.0.\n",
      "It will stay in the Private Preview phase. For future implementations, kindly utilize `snowflake.ml.registry.Registry`,\n",
      "except when specifically required. The old model registry will be removed once all its primary functionalities are\n",
      "fully integrated into the new registry.\n",
      "        \n",
      "  registry = model_registry.ModelRegistry(\n",
      "INFO:snowflake.connector.cursor:query: [SHOW DATABASES LIKE 'DASH_DB']\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "WARNING:absl:The database DASH_DB already exists. Skipping creation.\n",
      "INFO:snowflake.connector.cursor:query: [SHOW SCHEMAS LIKE 'DASH_SCHEMA' IN DATABASE DASH_DB]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "WARNING:absl:The schema DASH_DB.DASH_SCHEMA already exists. Skipping creation.\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 13\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 8\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 9\n",
      "INFO:snowflake.connector.cursor:query: [DESC TABLE DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_ARTIFACTS]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 7\n",
      "INFO:snowflake.connector.cursor:query: [SHOW DATABASES LIKE 'DASH_DB']\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW SCHEMAS LIKE 'DASH_SCHEMA' IN DATABASE DASH_DB]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_MODELS' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_METADATA' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_DEPLOYMENTS' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA_L...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE TEMPORARY VIEW DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_ARTIFACTS_...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"LLAMA2_7b_CHAT\"\n",
    "MODEL_VERSION = \"FineTunedV1.1\"\n",
    "DEPLOYMENT_NAME = \"FINETUNED_LLAMA2\"\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=SNOWFLAKE_DATABASE, \n",
    "    schema_name=SNOWFLAKE_SCHEMA, \n",
    "    create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"MODEL_NAME\", \"MODEL_VERSION\", \"DEPLOYMENT_NAME\", \"CREATION_TIME\", \"TARGE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>MODEL_VERSION</th>\n",
       "      <th>DEPLOYMENT_NAME</th>\n",
       "      <th>CREATION_TIME</th>\n",
       "      <th>TARGET_METHOD</th>\n",
       "      <th>TARGET_PLATFORM</th>\n",
       "      <th>SIGNATURE</th>\n",
       "      <th>OPTIONS</th>\n",
       "      <th>STAGE_PATH</th>\n",
       "      <th>ROLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MODEL_NAME, MODEL_VERSION, DEPLOYMENT_NAME, CREATION_TIME, TARGET_METHOD, TARGET_PLATFORM, SIGNATURE, OPTIONS, STAGE_PATH, ROLE]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.list_deployments(model_name=MODEL_NAME,model_version=MODEL_VERSION).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# registry.delete_deployment(model_name=MODEL_NAME,model_version=MODEL_VERSION,deployment_name=DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATION_CONTEXT</th>\n",
       "      <th>CREATION_ENVIRONMENT_SPEC</th>\n",
       "      <th>CREATION_ROLE</th>\n",
       "      <th>CREATION_TIME</th>\n",
       "      <th>ID</th>\n",
       "      <th>INPUT_SPEC</th>\n",
       "      <th>NAME</th>\n",
       "      <th>OUTPUT_SPEC</th>\n",
       "      <th>RUNTIME_ENVIRONMENT_SPEC</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>URI</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>ARTIFACT_IDS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>METRICS</th>\n",
       "      <th>TAGS</th>\n",
       "      <th>REGISTRATION_TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.10.13\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-14 15:29:38.425000-08:00</td>\n",
       "      <td>a9b776ce834511ee9c921204c7b8f46d</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_A9B776CE834511EE9C921204C7B8F46D</td>\n",
       "      <td>BaseV1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-14 15:29:39.837000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.8.16\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-15 11:04:42.250000-08:00</td>\n",
       "      <td>d26762d883e911ee8f5ace7db0e7935f</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D26762D883E911EE8F5ACE7DB0E7935F</td>\n",
       "      <td>BestTunedV1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-15 11:04:44.853000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.18\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-14 16:49:14.883000-08:00</td>\n",
       "      <td>c6ca82aa835011eeac5d1204c7b8f46d</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C6CA82AA835011EEAC5D1204C7B8F46D</td>\n",
       "      <td>BaseV2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-14 16:49:16.186000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.18\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-27 06:38:13.856000-08:00</td>\n",
       "      <td>934a1d828d3211ee9d301204c7b8f46e</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_934A1D828D3211EE9D301204C7B8F46E</td>\n",
       "      <td>NewBaseV2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-27 06:38:15.860000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.10.11\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2024-03-06 16:16:55.387000-08:00</td>\n",
       "      <td>ff92534adc1711ee93c05ad1a0b84c26</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_FF92534ADC1711EE93C05AD1A0B84C26</td>\n",
       "      <td>FineTunedV1.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-06 16:16:56.386000-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.10.11\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2024-03-27 15:03:33.324000-07:00</td>\n",
       "      <td>d997d326ec8511ee95b1369145349ce2</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2</td>\n",
       "      <td>BaseV1.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-03-27 15:03:34.479000-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>{\\n  \"python\": \"3.9.18\"\\n}</td>\n",
       "      <td>\"DASH_SPCS\"</td>\n",
       "      <td>2023-11-16 09:23:06.204000-08:00</td>\n",
       "      <td>c70d0bf284a411eebb681204c7b8f46d</td>\n",
       "      <td>None</td>\n",
       "      <td>LLAMA2_7b_CHAT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>llm</td>\n",
       "      <td>sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C70D0BF284A411EEBB681204C7B8F46D</td>\n",
       "      <td>NewBaseV1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-11-16 09:23:07.145000-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREATION_CONTEXT    CREATION_ENVIRONMENT_SPEC CREATION_ROLE  \\\n",
       "0             None  {\\n  \"python\": \"3.10.13\"\\n}   \"DASH_SPCS\"   \n",
       "1             None   {\\n  \"python\": \"3.8.16\"\\n}   \"DASH_SPCS\"   \n",
       "2             None   {\\n  \"python\": \"3.9.18\"\\n}   \"DASH_SPCS\"   \n",
       "3             None   {\\n  \"python\": \"3.9.18\"\\n}   \"DASH_SPCS\"   \n",
       "4             None  {\\n  \"python\": \"3.10.11\"\\n}   \"DASH_SPCS\"   \n",
       "5             None  {\\n  \"python\": \"3.10.11\"\\n}   \"DASH_SPCS\"   \n",
       "6             None   {\\n  \"python\": \"3.9.18\"\\n}   \"DASH_SPCS\"   \n",
       "\n",
       "                     CREATION_TIME                                ID  \\\n",
       "0 2023-11-14 15:29:38.425000-08:00  a9b776ce834511ee9c921204c7b8f46d   \n",
       "1 2023-11-15 11:04:42.250000-08:00  d26762d883e911ee8f5ace7db0e7935f   \n",
       "2 2023-11-14 16:49:14.883000-08:00  c6ca82aa835011eeac5d1204c7b8f46d   \n",
       "3 2023-11-27 06:38:13.856000-08:00  934a1d828d3211ee9d301204c7b8f46e   \n",
       "4 2024-03-06 16:16:55.387000-08:00  ff92534adc1711ee93c05ad1a0b84c26   \n",
       "5 2024-03-27 15:03:33.324000-07:00  d997d326ec8511ee95b1369145349ce2   \n",
       "6 2023-11-16 09:23:06.204000-08:00  c70d0bf284a411eebb681204c7b8f46d   \n",
       "\n",
       "  INPUT_SPEC            NAME OUTPUT_SPEC RUNTIME_ENVIRONMENT_SPEC TYPE  \\\n",
       "0       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "1       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "2       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "3       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "4       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "5       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "6       None  LLAMA2_7b_CHAT        None                     None  llm   \n",
       "\n",
       "                                                                       URI  \\\n",
       "0  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_A9B776CE834511EE9C921204C7B8F46D   \n",
       "1  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D26762D883E911EE8F5ACE7DB0E7935F   \n",
       "2  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C6CA82AA835011EEAC5D1204C7B8F46D   \n",
       "3  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_934A1D828D3211EE9D301204C7B8F46E   \n",
       "4  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_FF92534ADC1711EE93C05AD1A0B84C26   \n",
       "5  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_D997D326EC8511EE95B1369145349CE2   \n",
       "6  sfc://DASH_DB.DASH_SCHEMA.SNOWML_MODEL_C70D0BF284A411EEBB681204C7B8F46D   \n",
       "\n",
       "         VERSION ARTIFACT_IDS DESCRIPTION METRICS  TAGS  \\\n",
       "0       BaseV1.0         None        None    None  None   \n",
       "1  BestTunedV1.0         None        None    None  None   \n",
       "2       BaseV2.0         None        None    None  None   \n",
       "3    NewBaseV2.0         None        None    None  None   \n",
       "4  FineTunedV1.1         None        None    None  None   \n",
       "5       BaseV1.1         None        None    None  None   \n",
       "6    NewBaseV1.0         None        None    None  None   \n",
       "\n",
       "            REGISTRATION_TIMESTAMP  \n",
       "0 2023-11-14 15:29:39.837000-08:00  \n",
       "1 2023-11-15 11:04:44.853000-08:00  \n",
       "2 2023-11-14 16:49:16.186000-08:00  \n",
       "3 2023-11-27 06:38:15.860000-08:00  \n",
       "4 2024-03-06 16:16:56.386000-08:00  \n",
       "5 2024-03-27 15:03:34.479000-07:00  \n",
       "6 2023-11-16 09:23:07.145000-08:00  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.list_models().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [DELETE FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS WHERE ID='25071a9eec8e11...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [DROP STAGE DASH_DB.DASH_SCHEMA.SNOWML_MODEL_25071A9EEC8E11EE95B1369145349CE2]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA ( ATTRIBUTE_NAME,EVENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    }
   ],
   "source": [
    "registry.delete_model(model_name=MODEL_NAME,model_version='FineTunedV1.1',delete_artifact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Llama 2 from Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Referencing our fine-tuned weights and using the Hugging Face token to merge them with base Llama 2 model\n",
    "\n",
    "options = llm.LLMOptions(\n",
    "    token=HUGGING_FACE_TOKEN,\n",
    "    max_batch_size=100,\n",
    ")\n",
    "\n",
    "llama_model = llm.LLM(\n",
    "    model_id_or_path='output_weights_dir',\n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log and Deploy fine-tuned Llama 2 model using Model Registry\n",
    "\n",
    "Logging and deploying fine-tuned model with our setup may take ~15mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT  *  FROM (SELECT * FROM DASH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE STAGE DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:absl:Model signatures are auto inferred as:\n",
      "\n",
      "{'infer': ModelSignature(\n",
      "                    inputs=[\n",
      "                        FeatureSpec(dtype=DataType.STRING, name='input')\n",
      "                    ],\n",
      "                    outputs=[\n",
      "                        FeatureSpec(dtype=DataType.STRING, name='generated_text')\n",
      "                    ]\n",
      "                )}\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpbscx8kbm/model.zip' '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpbscx8kbm/MANIFEST.yml' '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8B...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpbscx8kbm/runtimes/python_runtime/env/conda.yml' '@DASH_DB.DA...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpbscx8kbm/runtimes/python_runtime/env/requirements.txt' '@DAS...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [PUT 'file:///tmp/tmpbscx8kbm/functions/infer.py' '@DASH_DB.DASH_SCHEMA.SNOWML_MO...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT  *  FROM (SELECT * FROM DASH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS ( CREATION_ENVIRONMENT_S...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA ( ATTRIBUTE_NAME,EVENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE STAGE IF NOT EXISTS DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS_STAG...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [LIST @DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [ls @DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2/MANIFEST...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2/function...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2/model.zi...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2/runtimes...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [GET '@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2/runtimes...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SHOW PARAMETERS LIKE 'PYTHON_CONNECTOR_QUERY_RESULT_FORMAT' IN SESSION]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS ( CREATION_TIME,DEP...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM (SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_MODELS_VIEW)...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [INSERT INTO DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_METADATA ( ATTRIBUTE_NAME,EVENT...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.97 s, sys: 0 ns, total: 1.97 s\n",
      "Wall time: 10min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'DASH_DB.DASH_SCHEMA.FINETUNED_LLAMA2',\n",
       " 'platform': <TargetPlatform.SNOWPARK_CONTAINER_SERVICES: 'SNOWPARK_CONTAINER_SERVICES'>,\n",
       " 'target_method': 'infer',\n",
       " 'signature': ModelSignature(\n",
       "                     inputs=[\n",
       "                         FeatureSpec(dtype=DataType.STRING, name='input')\n",
       "                     ],\n",
       "                     outputs=[\n",
       "                         FeatureSpec(dtype=DataType.STRING, name='generated_text')\n",
       "                     ]\n",
       "                 ),\n",
       " 'options': {'compute_pool': 'DASH_GPU3',\n",
       "  'num_gpus': 1,\n",
       "  'external_access_integrations': ['ALLOW_ALL_ACCESS_INTEGRATION']},\n",
       " 'details': {'service_info': {'name': 'SERVICE_8BFE1284EC8E11EE95B1369145349CE2',\n",
       "   'database_name': 'DASH_DB',\n",
       "   'schema_name': 'DASH_SCHEMA',\n",
       "   'owner': 'DASH_SPCS',\n",
       "   'compute_pool': 'DASH_GPU3',\n",
       "   'spec': '---\\nspec:\\n  containers:\\n  - name: \"inference-server\"\\n    image: \"sfsenorthamerica-build-spcs.registry.snowflakecomputing.com/dash_db/dash_schema/snowml_repo/4d71df997ca151dd6eea84d2f18ad40522ba1171:latest\"\\n    sha256: \"@sha256:47c23bbc633c78e0a7e410bc8a7207b7a778414e14e93ae5e7b8fbc215eee4a4\"\\n    env:\\n      MODEL_ZIP_STAGE_PATH: \"/DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2/model.zip\"\\n      NUM_WORKERS: \"1\"\\n      SNOWML_USE_GPU: \"true\"\\n      TARGET_METHOD: \"infer\"\\n      _CONCURRENT_REQUESTS_MAX: \"1\"\\n    readinessProbe:\\n      port: 5000\\n      path: \"/health\"\\n    resources:\\n      limits:\\n        nvidia.com/gpu: \"1\"\\n      requests:\\n        nvidia.com/gpu: \"1\"\\n    volumeMounts:\\n    - name: \"vol1\"\\n      mountPath: \"/local/user/vol1\"\\n    - name: \"stage\"\\n      mountPath: \"DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2\"\\n  volumes:\\n  - name: \"vol1\"\\n    source: \"local\"\\n  - name: \"stage\"\\n    source: \"@DASH_DB.DASH_SCHEMA.SNOWML_MODEL_8BFE1284EC8E11EE95B1369145349CE2\"\\n    uid: 1000\\n    gid: 1000\\n  endpoints:\\n  - name: \"predict\"\\n    port: 5000\\n    public: false\\n',\n",
       "   'dns_name': 'service-8bfe1284ec8e11ee95b1369145349ce2.dash-schema.dash-db.snowflakecomputing.internal',\n",
       "   'min_instances': 1,\n",
       "   'max_instances': 1,\n",
       "   'auto_resume': 'true',\n",
       "   'external_access_integrations': '[\"ALLOW_ALL_ACCESS_INTEGRATION\"]',\n",
       "   'created_on': datetime.datetime(2024, 3, 27, 16, 5, 54, 362000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>),\n",
       "   'updated_on': datetime.datetime(2024, 3, 27, 16, 5, 55, 370000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>),\n",
       "   'resumed_on': None,\n",
       "   'comment': None,\n",
       "   'owner_role_type': 'ROLE',\n",
       "   'query_warehouse': None},\n",
       "  'service_function_sql': \"\\nCREATE OR REPLACE FUNCTION DASH_DB.DASH_SCHEMA.FINETUNED_LLAMA2(input OBJECT)\\n    RETURNS OBJECT\\n    SERVICE=DASH_DB.DASH_SCHEMA.service_8bfe1284ec8e11ee95b1369145349ce2\\n    ENDPOINT=predict\\n    MAX_BATCH_ROWS = 100\\n    AS '/predict'\\n\"}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# log model in registry\n",
    "llama_model_ref = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model,\n",
    "    conda_dependencies=['sentencepiece']\n",
    ")\n",
    "\n",
    "# deploy model\n",
    "llama_model_ref.deploy(\n",
    "    deployment_name=DEPLOYMENT_NAME, \n",
    "    platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    permanent=True, \n",
    "    options={\"compute_pool\": SNOWFLAKE_COMPUTE_POOL, \"num_gpus\": 1, \"external_access_integrations\": [\"ALLOW_ALL_ACCESS_INTEGRATION\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if the model is already deployed, you may reference it using Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llama_model_ref = model_registry.ModelReference(\n",
    "#     registry=registry, \n",
    "#     model_name=MODEL_NAME, \n",
    "#     model_version=MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Eval Dataset using fine-tuned Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97/3143168716.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_df['input'] = eval_df.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Jack, and I'm looking for a toy for my niece.\\nfrosty: Hello Jack! I'm Frosty, and I'd be happy to help you find the perfect toy. Where are you calling from?\\ncaller: I'm calling from Cape Town, South Africa.\\nfrosty: Thank you, Jack from Cape Town! Can you tell me a bit about your niece's interests so we can find a great toy for her?\\ncaller: She's really into animals and likes playing pretend with her toys.\\nfrosty: How about the Fisher-Price Little People Mickey and Friends Playset? This playset features animal characters and is perfect for encouraging imaginative play.\\ncaller: That sounds nice, but I think she'd prefer something focused on real animals.\\nfrosty: In that case, the Calico Critters Pony's Stylish Hair Salon may be just the toy you're looking for. It comes with pony figurines and a cute hair salon for them.\\ncaller: Oh, that sounds perfect! Let's go with the pony's hair salon.\\nfrosty: Great choice! We've added the Calico Critters Pony's Stylish Hair Salon to your holiday wish list. Before we finish though, can you tell me how you plan to celebrate the holiday season?\\ncaller: Sure, I'll be spending the holidays at the beach with my family and enjoying the warm weather.\\nfrosty: That sounds amazing! To confirm, your toy list includes the Calico Critters Pony's Stylish Hair Salon. Is that correct?\\ncaller: Yes, that's correct. Thank you!+\\nfrosty: You're welcome, Jack! It's been a pleasure assisting you. Have a fantastic holiday season!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi Frosty, I'm Emily.\\nfrosty: Hello Emily! I'm here to help you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Sydney, Australia.\\nfrosty: Thank you, Emily from Sydney! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for a toy that's educational and fun for my son. He's really into science and technology.\\nfrosty: How about the Thames &amp; Kosmos Candy Vending Machine STEM experiment kit? It combines science and technology with creating a candy vending machine!\\ncaller: That sounds great, but I'd like to explore some more options before deciding.\\nfrosty: Sure thing! We also have the LeapFrog Magic Adventures Microscope, which allows kids to explore the world of science up-close with a real working microscope.\\ncaller: I think the magic microscope is the one! Let's add that to my wish list.\\nfrosty: Fantastic choice! I've added the LeapFrog Magic Adventures Microscope to your list. Before we wrap up, tell me a bit about your favorite way to spend time during the holiday season.\\ncaller: I enjoy baking holiday treats and watching seasonal movies with my family.\\nfrosty: That sounds delightful! To confirm, your toy list includes the LeapFrog Magic Adventures Microscope. Is everything correct?\\ncaller: Yes, it is. Thanks for your help, Frosty!\\nfrosty: You're welcome, Emily! Have a wonderful holiday season!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi, I'm David!\\nfrosty: Hello David! I'm Frosty, and I'm here to help you submit your holiday wish list. Can you tell me where you're calling from?\\ncaller: I'm calling from Auckland, New Zealand.\\nfrosty: Thank you, David from Auckland. What item would you like to add to your holiday wish list?\\ncaller: I want to get a fun toy for my daughter, but I'm not sure what to choose.\\nfrosty: No worries, let's explore a few options together. What are some of your daughter's interests?\\ncaller: She loves playing with dolls and watching animated shows.\\nfrosty: How about the Gabbys Dollhouse Cruise Ship? It's based on the popular animated show and offers imaginative play with a fun cruise ship and doll figurines.\\ncaller: That sounds good, but I'd like to see more options, please.\\nfrosty: Of course! You might also consider the Bluey Ultimate Lights and Sounds Playhouse, based on the popular animated show Bluey. It has interactive lights and sounds that bring the playhouse to life.\\ncaller: Those both sound good, but I think my daughter would prefer the gabby dollhouse.\\nfrosty: Great choice! I've added the Gabbys Dollhouse Cruise Ship to your holiday wish list. Now, tell me about your favorite holiday memory.\\ncaller: My favorite memory is when we all went ice skating together as a family during the holidays.\\nfrosty: Sounds like a wonderful experience! To confirm, your toy list includes the Gabbys Dollhouse Cruise Ship. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Excellent! Your wish list is all set. Have a fantastic holiday season, David!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hello, my name is Sarah.\\nfrosty: Hi Sarah! I'm Frosty, a voice bot here to assist you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Los Angeles, United States.\\nfrosty: Thank you, Sarah from Los Angeles! Let's get started on your wish list. What's the first item you have in mind?\\ncaller: I'm thinking of getting the pokemon plushie for my son, but I'm not sure.\\nfrosty: The Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack is an excellent choice for Pok\\u00e9mon fans! What do you think your son will enjoy the most about this toy?\\ncaller: He loves collecting Pok\\u00e9mon toys and watching the animated series, so I think he'd enjoy adding this to his collection.\\nfrosty: That's a great reason to choose this toy! How do you and your family plan to celebrate the holiday season?\\ncaller: We'll be hosting a game night and enjoying holiday treats with our loved ones.\\nfrosty: That sounds like a great way to spend the holidays! To confirm, your toy list includes the Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Wonderful! Your toys have been added to your holiday wish list. Happy holidays, Sarah!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.</td>\n",
       "      <td>\\n[INST] &lt;&lt;SYS&gt;&gt;\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n&lt;&lt;/SYS&gt;&gt;\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Liam.\\nfrosty: Hello Liam! I'm Frosty, and I'm here to help you submit your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Dublin, Ireland.\\nfrosty: Thank you, Liam from Dublin! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for something for my younger sister, but I'm not quite sure what she'd like.\\nfrosty: I'm here to help! Can you tell me a bit about your sister's interests and hobbies?\\ncaller: She loves arts and crafts, and she also enjoys watching nature documentaries.\\nfrosty: How about the National Geographic Mega Slime Kit &amp; Putty Lab? It combines her love for crafts and nature with fun, slime-filled experiments.\\ncaller: That sounds interesting, but let's explore some more options.\\nfrosty: We also have the Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set, which allows her to create and learn using eco-friendly foam.\\ncaller: I believe the playfoam letters would be a perfect match! Let's add that to the list.\\nfrosty: Wonderful! We've added the Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set to your holiday wish list. Before we finish, can you tell me one of your favorite holiday memories?\\ncaller: My favorite holiday memory was when my family and I went to visit the local Christmas markets and enjoyed a cozy evening together.\\nfrosty: Sounds lovely! To confirm, your toy list includes the Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set. Is that correct?\\ncaller: Yes, that's correct!\\nfrosty: Fantastic! Your toy list is complete. Have a happy holiday season, Liam!\"\\n### Output:\\n</td>\n",
       "      <td>{\"toy_list\": [\"Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers\"], \"location\": \"Dublin\"}</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          instruction  \\\n",
       "0  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "1  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "2  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "3  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "4  Extract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   input  \\\n",
       "0                                                                                                   \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Jack, and I'm looking for a toy for my niece.\\nfrosty: Hello Jack! I'm Frosty, and I'd be happy to help you find the perfect toy. Where are you calling from?\\ncaller: I'm calling from Cape Town, South Africa.\\nfrosty: Thank you, Jack from Cape Town! Can you tell me a bit about your niece's interests so we can find a great toy for her?\\ncaller: She's really into animals and likes playing pretend with her toys.\\nfrosty: How about the Fisher-Price Little People Mickey and Friends Playset? This playset features animal characters and is perfect for encouraging imaginative play.\\ncaller: That sounds nice, but I think she'd prefer something focused on real animals.\\nfrosty: In that case, the Calico Critters Pony's Stylish Hair Salon may be just the toy you're looking for. It comes with pony figurines and a cute hair salon for them.\\ncaller: Oh, that sounds perfect! Let's go with the pony's hair salon.\\nfrosty: Great choice! We've added the Calico Critters Pony's Stylish Hair Salon to your holiday wish list. Before we finish though, can you tell me how you plan to celebrate the holiday season?\\ncaller: Sure, I'll be spending the holidays at the beach with my family and enjoying the warm weather.\\nfrosty: That sounds amazing! To confirm, your toy list includes the Calico Critters Pony's Stylish Hair Salon. Is that correct?\\ncaller: Yes, that's correct. Thank you!+\\nfrosty: You're welcome, Jack! It's been a pleasure assisting you. Have a fantastic holiday season!\"\\n### Output:\\n   \n",
       "1                                                                                                                                                                                                  \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi Frosty, I'm Emily.\\nfrosty: Hello Emily! I'm here to help you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Sydney, Australia.\\nfrosty: Thank you, Emily from Sydney! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for a toy that's educational and fun for my son. He's really into science and technology.\\nfrosty: How about the Thames & Kosmos Candy Vending Machine STEM experiment kit? It combines science and technology with creating a candy vending machine!\\ncaller: That sounds great, but I'd like to explore some more options before deciding.\\nfrosty: Sure thing! We also have the LeapFrog Magic Adventures Microscope, which allows kids to explore the world of science up-close with a real working microscope.\\ncaller: I think the magic microscope is the one! Let's add that to my wish list.\\nfrosty: Fantastic choice! I've added the LeapFrog Magic Adventures Microscope to your list. Before we wrap up, tell me a bit about your favorite way to spend time during the holiday season.\\ncaller: I enjoy baking holiday treats and watching seasonal movies with my family.\\nfrosty: That sounds delightful! To confirm, your toy list includes the LeapFrog Magic Adventures Microscope. Is everything correct?\\ncaller: Yes, it is. Thanks for your help, Frosty!\\nfrosty: You're welcome, Emily! Have a wonderful holiday season!\"\\n### Output:\\n   \n",
       "2               \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hi, I'm David!\\nfrosty: Hello David! I'm Frosty, and I'm here to help you submit your holiday wish list. Can you tell me where you're calling from?\\ncaller: I'm calling from Auckland, New Zealand.\\nfrosty: Thank you, David from Auckland. What item would you like to add to your holiday wish list?\\ncaller: I want to get a fun toy for my daughter, but I'm not sure what to choose.\\nfrosty: No worries, let's explore a few options together. What are some of your daughter's interests?\\ncaller: She loves playing with dolls and watching animated shows.\\nfrosty: How about the Gabbys Dollhouse Cruise Ship? It's based on the popular animated show and offers imaginative play with a fun cruise ship and doll figurines.\\ncaller: That sounds good, but I'd like to see more options, please.\\nfrosty: Of course! You might also consider the Bluey Ultimate Lights and Sounds Playhouse, based on the popular animated show Bluey. It has interactive lights and sounds that bring the playhouse to life.\\ncaller: Those both sound good, but I think my daughter would prefer the gabby dollhouse.\\nfrosty: Great choice! I've added the Gabbys Dollhouse Cruise Ship to your holiday wish list. Now, tell me about your favorite holiday memory.\\ncaller: My favorite memory is when we all went ice skating together as a family during the holidays.\\nfrosty: Sounds like a wonderful experience! To confirm, your toy list includes the Gabbys Dollhouse Cruise Ship. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Excellent! Your wish list is all set. Have a fantastic holiday season, David!\"\\n### Output:\\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                          \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hello, my name is Sarah.\\nfrosty: Hi Sarah! I'm Frosty, a voice bot here to assist you with your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Los Angeles, United States.\\nfrosty: Thank you, Sarah from Los Angeles! Let's get started on your wish list. What's the first item you have in mind?\\ncaller: I'm thinking of getting the pokemon plushie for my son, but I'm not sure.\\nfrosty: The Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack is an excellent choice for Pok\\u00e9mon fans! What do you think your son will enjoy the most about this toy?\\ncaller: He loves collecting Pok\\u00e9mon toys and watching the animated series, so I think he'd enjoy adding this to his collection.\\nfrosty: That's a great reason to choose this toy! How do you and your family plan to celebrate the holiday season?\\ncaller: We'll be hosting a game night and enjoying holiday treats with our loved ones.\\nfrosty: That sounds like a great way to spend the holidays! To confirm, your toy list includes the Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack. Is that correct?\\ncaller: Yes, that's correct.\\nfrosty: Wonderful! Your toys have been added to your holiday wish list. Happy holidays, Sarah!\"\\n### Output:\\n   \n",
       "4  \\n[INST] <<SYS>>\\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n<</SYS>>\\n### Instruction:\\nExtract JSON response with 'location' and 'toy_list' as keys. 'location': Location of the caller. Include city only.'toy_list': List of toy names from the caller.\\n### Input:\\n\"caller: Hey, I'm Liam.\\nfrosty: Hello Liam! I'm Frosty, and I'm here to help you submit your holiday wish list. Where are you calling from?\\ncaller: I'm calling from Dublin, Ireland.\\nfrosty: Thank you, Liam from Dublin! What's the first item you'd like to add to your wish list?\\ncaller: I'm looking for something for my younger sister, but I'm not quite sure what she'd like.\\nfrosty: I'm here to help! Can you tell me a bit about your sister's interests and hobbies?\\ncaller: She loves arts and crafts, and she also enjoys watching nature documentaries.\\nfrosty: How about the National Geographic Mega Slime Kit & Putty Lab? It combines her love for crafts and nature with fun, slime-filled experiments.\\ncaller: That sounds interesting, but let's explore some more options.\\nfrosty: We also have the Playfoam Naturals Shape & Learn Letters & Numbers set, which allows her to create and learn using eco-friendly foam.\\ncaller: I believe the playfoam letters would be a perfect match! Let's add that to the list.\\nfrosty: Wonderful! We've added the Playfoam Naturals Shape & Learn Letters & Numbers set to your holiday wish list. Before we finish, can you tell me one of your favorite holiday memories?\\ncaller: My favorite holiday memory was when my family and I went to visit the local Christmas markets and enjoyed a cozy evening together.\\nfrosty: Sounds lovely! To confirm, your toy list includes the Playfoam Naturals Shape & Learn Letters & Numbers set. Is that correct?\\ncaller: Yes, that's correct!\\nfrosty: Fantastic! Your toy list is complete. Have a happy holiday season, Liam!\"\\n### Output:\\n   \n",
       "\n",
       "                                                                                            output  \\\n",
       "0             {\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}   \n",
       "1                     {\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}   \n",
       "2                           {\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}   \n",
       "3  {\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}   \n",
       "4        {\"toy_list\": [\"Playfoam Naturals Shape & Learn Letters & Numbers\"], \"location\": \"Dublin\"}   \n",
       "\n",
       "  language  \n",
       "0       EN  \n",
       "1       EN  \n",
       "2       EN  \n",
       "3       EN  \n",
       "4       EN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['input'] = eval_df.apply(\n",
    "    lambda x: eval_prompt.format(\n",
    "        instruction=x[\"instruction\"],\n",
    "        input_=x[\"input\"].replace('\\\\n', '\\n')\n",
    "    ), axis=1\n",
    ")\n",
    "eval_df.reset_index(drop=True, inplace=True)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [SHOW TABLES LIKE '_SYSTEM_REGISTRY_SCHEMA_VERSION' IN DASH_DB.DASH_SCHEMA]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT MAX(VERSION) AS MAX_VERSION FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT * FROM DASH_DB.DASH_SCHEMA._SYSTEM_REGISTRY_DEPLOYMENTS_VIEW]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT count(1) AS \"COUNT(LITERAL())\" FROM ( SELECT \"MODEL_NAME\", \"MODEL_VERSION...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"MODEL_NAME\", \"MODEL_VERSION\", \"DEPLOYMENT_NAME\", \"CREATION_TIME\", \"TARGE...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [CREATE TEMP STAGE /* Python:snowflake.connector.pandas_tools.write_pandas() */ \"...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [PUT /* Python:snowflake.connector.pandas_tools.write_pandas() */ 'file:///tmp/tm...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [CREATE TEMP FILE FORMAT \"DASH_DB\".\"DASH_SCHEMA\".\"kowebektby\" /* Python:snowflake...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT COLUMN_NAME, TYPE FROM table(infer_schema(location=>'@\"DASH_DB\".\"DASH_SCH...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 4\n",
      "INFO:snowflake.connector.cursor:query: [CREATE TEMPORARY TABLE IF NOT EXISTS \"DASH_DB\".\"DASH_SCHEMA\".\"SNOWPARK_TEMP_TABL...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [COPY INTO \"DASH_DB\".\"DASH_SCHEMA\".\"SNOWPARK_TEMP_TABLE_CISB4BBW7O\" /* Python:sno...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 1\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  *  FROM \"DASH_DB\".\"DASH_SCHEMA\".\"SNOWPARK_TEMP_TABLE_CISB4BBW7O\"]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  CAST (\"instruction\" AS STRING) AS \"instruction\",  CAST (\"input\" AS STRIN...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  CAST (\"TMP_RESULT\"['generated_text'] AS STRING) AS \"generated_text\" FROM...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 100\n",
      "INFO:snowflake.connector.cursor:query: [SELECT  CAST (\"TMP_RESULT\"['generated_text'] AS STRING) AS \"generated_text\" FROM...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 0\n",
      "/tmp/ipykernel_97/1095496930.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_df['predicted'] = llama_model_ref.predict(deployment_name=DEPLOYMENT_NAME,data=eval_df)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}</td>\n",
       "      <td>\"location\": \"Cape Town\",\\n\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value of 'location' is 'Cape Town', which is the city provided by the caller. The value of 'toy_list' is a list containing only one toy,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}</td>\n",
       "      <td>\"location\": \"Sydney, Australia\",\\n\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value for 'location' is \"Sydney, Australia\", which is the city provided by the caller. The value for 'toy_list' is an array containing the single item \"Leap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}</td>\n",
       "      <td>\"location\": \"Auckland, New Zealand\",\\n\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with 'location' and 'toy_list' as keys.\\n\\n### Hint: You can use the 'location' key to extract the location of the caller, which is Auckland, New Zealand in this case. Similarly, you can use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}</td>\n",
       "      <td>\"{\\n'location': 'Los Angeles, United States',\\n'toy_list': ['Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack']\\n}\"\\n\\nPlease provide the JSON response with the extracted information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"toy_list\": [\"Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers\"], \"location\": \"Dublin\"}</td>\n",
       "      <td>\"location\": \"Dublin, Ireland\",\\n\"toy_list\": [\"Playfoam Naturals Shape &amp; Learn Letters &amp; Numbers set\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with the 'location' and 'toy_list' keys.\\n\\n### Expected Output:\\n{\"location\": \"Dublin, Ireland\", \"toy_list\": [\"Playfoam Naturals Shape &amp; Lear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            output  \\\n",
       "0             {\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"], \"location\": \"Cape Town\"}   \n",
       "1                     {\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"], \"location\": \"Sydney\"}   \n",
       "2                           {\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"], \"location\": \"Auckland\"}   \n",
       "3  {\"toy_list\": [\"Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack\"], \"location\": \"Los Angeles\"}   \n",
       "4        {\"toy_list\": [\"Playfoam Naturals Shape & Learn Letters & Numbers\"], \"location\": \"Dublin\"}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                               predicted  \n",
       "0                         \"location\": \"Cape Town\",\\n\"toy_list\": [\"Calico Critters Pony's Stylish Hair Salon\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value of 'location' is 'Cape Town', which is the city provided by the caller. The value of 'toy_list' is a list containing only one toy,  \n",
       "1  \"location\": \"Sydney, Australia\",\\n\"toy_list\": [\"LeapFrog Magic Adventures Microscope\"]\\n\\n### Explanation:\\nThe output includes the requested JSON response with the keys 'location' and 'toy_list'. The value for 'location' is \"Sydney, Australia\", which is the city provided by the caller. The value for 'toy_list' is an array containing the single item \"Leap  \n",
       "2                    \"location\": \"Auckland, New Zealand\",\\n\"toy_list\": [\"Gabbys Dollhouse Cruise Ship\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with 'location' and 'toy_list' as keys.\\n\\n### Hint: You can use the 'location' key to extract the location of the caller, which is Auckland, New Zealand in this case. Similarly, you can use  \n",
       "3                                                                                                                                                                              \"{\\n'location': 'Los Angeles, United States',\\n'toy_list': ['Pok\\u00e9mon 8-Inch Plush First Partner Three-Pack']\\n}\"\\n\\nPlease provide the JSON response with the extracted information.  \n",
       "4                                                 \"location\": \"Dublin, Ireland\",\\n\"toy_list\": [\"Playfoam Naturals Shape & Learn Letters & Numbers set\"]\\n\\n### Task:\\nUsing the provided input, extract the JSON response with the 'location' and 'toy_list' keys.\\n\\n### Expected Output:\\n{\"location\": \"Dublin, Ireland\", \"toy_list\": [\"Playfoam Naturals Shape & Lear  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['predicted'] = llama_model_ref.predict(deployment_name=DEPLOYMENT_NAME,data=eval_df)\n",
    "eval_df[['output', 'predicted']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
